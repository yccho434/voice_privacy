# timestamp_audio_pipeline.py
"""
íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ìŒì„±â†’í…ìŠ¤íŠ¸ í†µí•© íŒŒì´í”„ë¼ì¸
ë¬¸ì¥ë³„ ì‹œì‘ ì‹œê°„ í‘œì‹œ
"""

import os
import time
import json
from pathlib import Path
from typing import Optional, Dict, Callable, List
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta

# ëª¨ë“ˆ ì„í¬íŠ¸
from enhanced_audio_processor import EnhancedAudioProcessor
from smart_sentence_stt import SmartSentenceSTT


@dataclass
class TimestampConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    etri_api_key: str
    
    # ì²˜ë¦¬ ì˜µì…˜
    enhance_audio: bool = True
    aggressive_denoise: bool = False
    use_sentence_chunks: bool = True  # ë¬¸ì¥ ë‹¨ìœ„ ì²­í‚¹
    parallel_stt: bool = True
    max_workers: int = 2
    
    # ì¶œë ¥ ì˜µì…˜
    output_format: str = "timestamp"  # "timestamp", "srt", "plain"
    save_outputs: bool = True
    output_dir: str = "./output"


@dataclass  
class TimestampResult:
    """ì²˜ë¦¬ ê²°ê³¼"""
    success: bool
    
    # í…ìŠ¤íŠ¸ ê²°ê³¼
    plain_text: str  # ì¼ë°˜ í…ìŠ¤íŠ¸
    formatted_text: str  # [MM:SS] í¬í•¨ í…ìŠ¤íŠ¸
    srt_text: Optional[str]  # SRT ìë§‰ í˜•ì‹
    
    # ë¬¸ì¥ ì •ë³´
    sentences: List[Dict]  # ê° ë¬¸ì¥ë³„ ì •ë³´
    
    # íŒŒì¼ ê²½ë¡œ
    audio_path: str
    enhanced_audio_path: Optional[str]
    output_files: Dict[str, str]
    
    # í†µê³„
    total_duration: float
    processing_time: float
    sentence_count: int
    audio_improvement: Dict
    
    timestamp: str


class TimestampAudioPipeline:
    """íƒ€ì„ìŠ¤íƒ¬í”„ ìŒì„± ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: TimestampConfig):
        self.config = config
        self.audio_processor = EnhancedAudioProcessor(target_sr=16000)
        self.stt_processor = SmartSentenceSTT(config.etri_api_key)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬
        if config.save_outputs:
            Path(config.output_dir).mkdir(parents=True, exist_ok=True)
    
    def process(self,
                audio_path: str,
                progress_callback: Optional[Callable] = None) -> TimestampResult:
        """
        ìŒì„± íŒŒì¼ ì²˜ë¦¬ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        
        Args:
            audio_path: ì…ë ¥ ìŒì„± íŒŒì¼
            progress_callback: ì§„í–‰ ì½œë°±
            
        Returns:
            TimestampResult
        """
        start_time = time.time()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì§„í–‰ ìƒí™© ê´€ë¦¬
        def update_progress(percent: int, message: str):
            if progress_callback:
                progress_callback(percent, message)
        
        try:
            # 1ë‹¨ê³„: ìŒì„± í’ˆì§ˆ í–¥ìƒ
            enhanced_audio_path = None
            audio_improvement = {}
            
            if self.config.enhance_audio:
                update_progress(10, "ğŸµ ìŒì„± í’ˆì§ˆ í–¥ìƒ ì¤‘...")
                
                if self.config.save_outputs:
                    output_name = f"enhanced_{timestamp}_{Path(audio_path).stem}.wav"
                    enhanced_audio_path = os.path.join(self.config.output_dir, output_name)
                
                audio_data, metrics = self.audio_processor.process(
                    audio_path,
                    enhanced_audio_path,
                    aggressive=self.config.aggressive_denoise
                )
                
                audio_improvement = metrics.get('improvement', {})
                
                # STTìš© ì˜¤ë””ì˜¤
                if enhanced_audio_path:
                    audio_for_stt = enhanced_audio_path
                else:
                    import tempfile
                    import soundfile as sf
                    temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
                    sf.write(temp_file.name, audio_data, 16000)
                    audio_for_stt = temp_file.name
                
                update_progress(30, f"âœ… ë…¸ì´ì¦ˆ {audio_improvement.get('noise_reduction', 0):.1f}% ê°ì†Œ")
            else:
                audio_for_stt = audio_path
            
            # 2ë‹¨ê³„: ë¬¸ì¥ ë‹¨ìœ„ STT
            update_progress(40, "ğŸ¤ ë¬¸ì¥ ë‹¨ìœ„ ìŒì„± ì¸ì‹ ì‹œì‘...")
            
            # STT ì§„í–‰ ì½œë°±
            def stt_progress(current: int, total: int, message: str, eta: Optional[int]):
                base_percent = 40
                stt_range = 50  # 40% ~ 90%
                percent = base_percent + int((current / total) * stt_range)
                update_progress(percent, message)
            
            # ë¬¸ì¥ ë‹¨ìœ„ ì²˜ë¦¬
            if self.config.use_sentence_chunks:
                result = self.stt_processor.process_with_timestamps(
                    audio_for_stt,
                    language="korean",
                    max_workers=self.config.max_workers if self.config.parallel_stt else 1,
                    progress_callback=stt_progress
                )
                
                sentences = result.get('sentences', [])
                formatted_text = result.get('formatted_text', '')
                
            else:
                # í´ë°±: ê¸°ì¡´ ë°©ì‹ (íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì •)
                from improved_stt_processor import ImprovedSTTProcessor
                fallback_stt = ImprovedSTTProcessor(self.config.etri_api_key)
                result = fallback_stt.process(
                    audio_for_stt,
                    max_workers=self.config.max_workers if self.config.parallel_stt else 1,
                    progress_callback=stt_progress
                )
                
                # ë‹¨ìˆœ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì •
                text = result.get('text', '')
                sentences = self._estimate_timestamps(text, audio_for_stt)
                formatted_text = self._format_with_timestamps(sentences)
            
            # 3ë‹¨ê³„: ë‹¤ì–‘í•œ í˜•ì‹ ìƒì„±
            update_progress(90, "ğŸ“ ê²°ê³¼ í¬ë§·íŒ… ì¤‘...")
            
            plain_text = self._extract_plain_text(sentences)
            srt_text = self._generate_srt(sentences) if self.config.output_format == "srt" else None
            
            # 4ë‹¨ê³„: íŒŒì¼ ì €ì¥
            output_files = {}
            
            if self.config.save_outputs:
                base_name = f"transcript_{timestamp}_{Path(audio_path).stem}"
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í…ìŠ¤íŠ¸
                if formatted_text:
                    timestamp_file = os.path.join(self.config.output_dir, f"{base_name}_timestamp.txt")
                    with open(timestamp_file, 'w', encoding='utf-8') as f:
                        f.write(formatted_text)
                    output_files['timestamp'] = timestamp_file
                
                # ì¼ë°˜ í…ìŠ¤íŠ¸
                plain_file = os.path.join(self.config.output_dir, f"{base_name}_plain.txt")
                with open(plain_file, 'w', encoding='utf-8') as f:
                    f.write(plain_text)
                output_files['plain'] = plain_file
                
                # SRT ìë§‰
                if srt_text:
                    srt_file = os.path.join(self.config.output_dir, f"{base_name}.srt")
                    with open(srt_file, 'w', encoding='utf-8') as f:
                        f.write(srt_text)
                    output_files['srt'] = srt_file
                
                # JSON ë©”íƒ€ë°ì´í„°
                meta_file = os.path.join(self.config.output_dir, f"{base_name}_meta.json")
                meta_data = {
                    'timestamp': timestamp,
                    'audio_path': audio_path,
                    'sentences': sentences,
                    'audio_improvement': audio_improvement,
                    'processing_time': time.time() - start_time
                }
                with open(meta_file, 'w', encoding='utf-8') as f:
                    json.dump(meta_data, f, ensure_ascii=False, indent=2)
                output_files['meta'] = meta_file
            
            # ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚°
            try:
                import librosa
                y, sr = librosa.load(audio_path, sr=None)
                total_duration = len(y) / sr
            except:
                total_duration = sentences[-1]['end_time'] if sentences else 0
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if self.config.enhance_audio and not self.config.save_outputs:
                try:
                    os.remove(audio_for_stt)
                except:
                    pass
            
            update_progress(100, "âœ… ì²˜ë¦¬ ì™„ë£Œ!")
            
            return TimestampResult(
                success=True,
                plain_text=plain_text,
                formatted_text=formatted_text,
                srt_text=srt_text,
                sentences=sentences,
                audio_path=audio_path,
                enhanced_audio_path=enhanced_audio_path,
                output_files=output_files,
                total_duration=total_duration,
                processing_time=time.time() - start_time,
                sentence_count=len(sentences),
                audio_improvement=audio_improvement,
                timestamp=timestamp
            )
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            
            return TimestampResult(
                success=False,
                plain_text="",
                formatted_text="",
                srt_text=None,
                sentences=[],
                audio_path=audio_path,
                enhanced_audio_path=None,
                output_files={},
                total_duration=0,
                processing_time=time.time() - start_time,
                sentence_count=0,
                audio_improvement={},
                timestamp=timestamp
            )
    
    def _extract_plain_text(self, sentences: List[Dict]) -> str:
        """ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return " ".join(s['text'] for s in sentences if s.get('text'))
    
    def _format_with_timestamps(self, sentences: List[Dict]) -> str:
        """íƒ€ì„ìŠ¤íƒ¬í”„ í¬ë§·íŒ…"""
        lines = []
        
        for sentence in sentences:
            minutes = int(sentence['start_time'] // 60)
            seconds = int(sentence['start_time'] % 60)
            timestamp = f"[{minutes:02d}:{seconds:02d}]"
            
            lines.append(f"{timestamp} {sentence['text']}")
            lines.append("")  # ë¹ˆ ì¤„
        
        return "\n".join(lines)
    
    def _generate_srt(self, sentences: List[Dict]) -> str:
        """SRT ìë§‰ í˜•ì‹ ìƒì„±"""
        srt_lines = []
        
        for i, sentence in enumerate(sentences, 1):
            # ì‹œê°„ í¬ë§· (HH:MM:SS,mmm)
            start_time = self._format_srt_time(sentence['start_time'])
            end_time = self._format_srt_time(sentence.get('end_time', sentence['start_time'] + 3))
            
            srt_lines.append(str(i))
            srt_lines.append(f"{start_time} --> {end_time}")
            srt_lines.append(sentence['text'])
            srt_lines.append("")  # ë¹ˆ ì¤„
        
        return "\n".join(srt_lines)
    
    def _format_srt_time(self, seconds: float) -> str:
        """SRT ì‹œê°„ í˜•ì‹ ë³€í™˜"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
    
    def _estimate_timestamps(self, text: str, audio_path: str) -> List[Dict]:
        """í´ë°±: ë‹¨ìˆœ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì •"""
        try:
            import librosa
            y, sr = librosa.load(audio_path, sr=None)
            total_duration = len(y) / sr
        except:
            total_duration = 60  # ê¸°ë³¸ê°’
        
        # ë¬¸ì¥ ë¶„ë¦¬
        import re
        sentences_text = re.split(r'[.!?]+', text)
        sentences_text = [s.strip() for s in sentences_text if s.strip()]
        
        if not sentences_text:
            return []
        
        # ê· ë“± ë¶„ë°°
        time_per_sentence = total_duration / len(sentences_text)
        
        sentences = []
        current_time = 0
        
        for sent_text in sentences_text:
            sentences.append({
                'text': sent_text,
                'start_time': current_time,
                'end_time': current_time + time_per_sentence
            })
            current_time += time_per_sentence
        
        return sentences


# ê°„í¸ ì‚¬ìš© í•¨ìˆ˜
def process_audio_with_timestamps(
    audio_path: str,
    api_key: str,
    enhance_audio: bool = True,
    output_format: str = "timestamp",
    progress_callback: Optional[Callable] = None
) -> Dict:
    """
    íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ìŒì„± ì²˜ë¦¬
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼
        api_key: ETRI API í‚¤
        enhance_audio: ìŒì„± í–¥ìƒ ì—¬ë¶€
        output_format: ì¶œë ¥ í˜•ì‹ ("timestamp", "srt", "plain")
        progress_callback: ì§„í–‰ ì½œë°±
        
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    config = TimestampConfig(
        etri_api_key=api_key,
        enhance_audio=enhance_audio,
        output_format=output_format,
        use_sentence_chunks=True  # ë¬¸ì¥ ë‹¨ìœ„ ì²­í‚¹ ì‚¬ìš©
    )
    
    pipeline = TimestampAudioPipeline(config)
    result = pipeline.process(audio_path, progress_callback)
    
    return {
        'success': result.success,
        'formatted_text': result.formatted_text,
        'plain_text': result.plain_text,
        'sentences': result.sentences,
        'sentence_count': result.sentence_count,
        'duration': result.total_duration,
        'processing_time': result.processing_time,
        'files': result.output_files
    }


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python timestamp_audio_pipeline.py [ì˜¤ë””ì˜¤íŒŒì¼]")
        sys.exit(1)
    
    audio_file = sys.argv[1]
    api_key = os.getenv("ETRI_API_KEY")
    
    if not api_key:
        print("âŒ ETRI API í‚¤ ì„¤ì • í•„ìš”")
        sys.exit(1)
    
    print(f"ğŸµ ì²˜ë¦¬ ì‹œì‘: {audio_file}\n")
    
    # ì§„í–‰ í‘œì‹œ
    def show_progress(percent, message):
        bar_length = 30
        filled = int(bar_length * percent / 100)
        bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
        print(f"\r[{bar}] {percent:3d}% | {message}", end="", flush=True)
    
    # ì²˜ë¦¬
    result = process_audio_with_timestamps(
        audio_file,
        api_key,
        enhance_audio=True,
        output_format="timestamp",
        progress_callback=show_progress
    )
    
    print("\n\n" + "="*60)
    
    if result['success']:
        print("âœ… ì²˜ë¦¬ ì™„ë£Œ!\n")
        print(f"ğŸ“Š í†µê³„:")
        print(f"  - ë¬¸ì¥ ìˆ˜: {result['sentence_count']}ê°œ")
        print(f"  - ì˜¤ë””ì˜¤ ê¸¸ì´: {result['duration']:.1f}ì´ˆ")
        print(f"  - ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.1f}ì´ˆ")
        print(f"\nğŸ“ íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í…ìŠ¤íŠ¸:\n")
        print(result['formatted_text'][:1000])
        if len(result['formatted_text']) > 1000:
            print("\n... (ì´í•˜ ìƒëµ)")
    else:
        print("âŒ ì²˜ë¦¬ ì‹¤íŒ¨")