# speech_to_text.py
"""
ETRI ìŒì„±ì¸ì‹ API ëª¨ë“ˆ
ê¸´ ìŒì„± íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì²­í¬ ë¶„í•  ê¸°ëŠ¥ í¬í•¨
"""

import json
import base64
import urllib3
import time
import tempfile
import os
import sys
from typing import Optional, Dict, List, Callable
from pathlib import Path
from dataclasses import dataclass

# SSL ê²½ê³  ë¹„í™œì„±í™”
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# FFmpeg ìë™ ì„¤ì •
try:
    import imageio_ffmpeg
    ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()
    
    # pydubì— FFmpeg ê²½ë¡œ ì„¤ì •
    from pydub.utils import which
    from pydub import AudioSegment
    
    if not which("ffmpeg"):
        AudioSegment.converter = ffmpeg_path
        AudioSegment.ffmpeg = ffmpeg_path
        AudioSegment.ffprobe = ffmpeg_path.replace("ffmpeg", "ffprobe")
        print(f"âœ… FFmpeg ìë™ ì„¤ì • ì™„ë£Œ: {ffmpeg_path}")
    
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("âš ï¸ pydub ë˜ëŠ” imageio-ffmpeg ì„¤ì¹˜ í•„ìš”")

# Windows Chocolatey FFmpeg ê²½ë¡œ ì¶”ê°€ (í´ë°±)
if sys.platform == "win32" and PYDUB_AVAILABLE:
    choco_path = r"C:\ProgramData\chocolatey\bin"
    if os.path.exists(os.path.join(choco_path, "ffmpeg.exe")):
        os.environ["PATH"] = choco_path + os.pathsep + os.environ.get("PATH", "")


@dataclass
class ChunkResult:
    """ì²­í¬ ì²˜ë¦¬ ê²°ê³¼"""
    chunk_index: int
    text: str
    success: bool
    error: Optional[str] = None
    duration: float = 0.0


class ETRISpeechToText:
    """ETRI ìŒì„±ì¸ì‹ API í´ë¼ì´ì–¸íŠ¸"""
    
    API_URL = "http://epretx.etri.re.kr:8000/api/WiseASR_Recognition"
    MAX_CHUNK_SECONDS = 15  # ì²­í¬ í¬ê¸°ë¥¼ 15ì´ˆë¡œ ì¤„ì„ (ë” ì•ˆì „)
    OVERLAP_SECONDS = 3.0    # ì˜¤ë²„ë©ì„ 3ì´ˆë¡œ ëŒ€í­ ì¦ê°€
    REQUEST_DELAY = 1.0      # ìš”ì²­ ê°„ ë”œë ˆì´ (ì´ˆ)
    
    def __init__(self, access_key: str):
        """
        Args:
            access_key: ETRI API ì ‘ê·¼ í‚¤
        """
        self.access_key = access_key
        self.http = urllib3.PoolManager()
    
    def recognize(self, audio_file_path: str, language: str = "korean") -> Dict:
        """
        ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ê¸°ë³¸ ë©”ì„œë“œ)
        
        Args:
            audio_file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ (korean, english, japanese, chinese ë“±)
            
        Returns:
            {"success": bool, "text": str, "error": str}
        """
        try:
            # íŒŒì¼ ì½ê¸° ë° Base64 ì¸ì½”ë”©
            with open(audio_file_path, "rb") as f:
                audio_contents = base64.b64encode(f.read()).decode("utf8")
            
            # API ìš”ì²­ êµ¬ì„±
            request_json = {
                "argument": {
                    "language_code": language,
                    "audio": audio_contents
                }
            }
            
            # API í˜¸ì¶œ
            print(f"ğŸ” API í˜¸ì¶œ ì¤‘... ì–¸ì–´: {language}, íŒŒì¼: {audio_file_path}")
            response = self.http.request(
                "POST",
                self.API_URL,
                headers={
                    "Content-Type": "application/json; charset=UTF-8",
                    "Authorization": self.access_key
                },
                body=json.dumps(request_json)
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            print(f"ğŸ“¡ ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status}")
            
            if response.status == 200:
                result = json.loads(response.data.decode("utf-8"))
                
                # ë””ë²„ê·¸: ì „ì²´ ì‘ë‹µ êµ¬ì¡° ì¶œë ¥
                print(f"ğŸ“‹ ì‘ë‹µ result ì½”ë“œ: {result.get('result')}")
                
                # ì„±ê³µ ì²´í¬
                if result.get("result", -1) == 0:
                    # ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    return_obj = result.get("return_object", {})
                    recognized_text = return_obj.get("recognized", "")
                    
                    # recognized í•„ë“œê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ í•„ë“œ í™•ì¸
                    if not recognized_text:
                        # ë‹¤ë¥¸ ê°€ëŠ¥í•œ í•„ë“œë“¤ í™•ì¸
                        recognized_text = return_obj.get("result", "")
                        if not recognized_text:
                            recognized_text = return_obj.get("text", "")
                        if not recognized_text:
                            print(f"âš ï¸ í…ìŠ¤íŠ¸ í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. return_object êµ¬ì¡°: {list(return_obj.keys())}")
                    
                    print(f"âœ… ì¸ì‹ ì„±ê³µ: {len(recognized_text)}ì")
                    
                    return {
                        "success": True,
                        "text": recognized_text,
                        "error": None
                    }
                else:
                    # ì˜¤ë¥˜ ìƒì„¸ ì •ë³´
                    error_msg = f"API Error Code: {result.get('result')}"
                    if result.get('reason'):
                        error_msg += f" - Reason: {result.get('reason')}"
                    if result.get('message'):
                        error_msg += f" - Message: {result.get('message')}"
                    
                    print(f"âŒ API ì˜¤ë¥˜: {error_msg}")
                    print(f"ğŸ“‹ ì „ì²´ ì‘ë‹µ: {json.dumps(result, ensure_ascii=False, indent=2)}")
                    
                    return {
                        "success": False,
                        "text": "",
                        "error": error_msg
                    }
            else:
                # HTTP ì˜¤ë¥˜ ìƒì„¸ ì •ë³´
                error_body = response.data.decode("utf-8")
                error_msg = f"HTTP Error {response.status}"
                
                try:
                    error_json = json.loads(error_body)
                    if error_json.get('message'):
                        error_msg += f": {error_json.get('message')}"
                    if error_json.get('error'):
                        error_msg += f" - {error_json.get('error')}"
                except:
                    error_msg += f": {error_body[:200]}"  # ì²˜ìŒ 200ìë§Œ
                
                print(f"âŒ HTTP ì˜¤ë¥˜: {error_msg}")
                
                return {
                    "success": False,
                    "text": "",
                    "error": error_msg
                }
                
        except FileNotFoundError:
            return {
                "success": False,
                "text": "",
                "error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}"
            }
        except Exception as e:
            return {
                "success": False,
                "text": "",
                "error": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def split_audio_smart(self, audio_path: str) -> List[str]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ë¶„í•  (ë¬´ìŒ êµ¬ê°„ í™œìš©)
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì²­í¬ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if not PYDUB_AVAILABLE:
            raise ImportError("pydubê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install pydub")
        
        from pydub.silence import detect_nonsilent
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_file(audio_path)
        duration_ms = len(audio)
        
        # ë¬´ìŒì´ ì•„ë‹Œ êµ¬ê°„ ê°ì§€
        nonsilent_ranges = detect_nonsilent(
            audio,
            min_silence_len=300,  # 0.3ì´ˆ ì´ìƒ ë¬´ìŒ
            silence_thresh=-40,    # dB
            seek_step=10
        )
        
        chunks = []
        temp_dir = tempfile.mkdtemp()
        chunk_index = 0
        
        # ìµœëŒ€ 15ì´ˆ, ìµœì†Œ 5ì´ˆ ì²­í¬
        max_chunk_ms = 15000
        min_chunk_ms = 5000
        target_overlap_ms = 3000  # 3ì´ˆ ì˜¤ë²„ë©
        
        current_start = 0
        
        print(f"ğŸ“Š ìŠ¤ë§ˆíŠ¸ ë¶„í• : ì´ {duration_ms/1000:.1f}ì´ˆ")
        
        while current_start < duration_ms:
            # ì´ìƒì ì¸ ë ì§€ì 
            ideal_end = min(current_start + max_chunk_ms, duration_ms)
            
            # ì‹¤ì œ ë ì§€ì  ì°¾ê¸° (ë¬´ìŒ êµ¬ê°„ ì°¾ê¸°)
            actual_end = ideal_end
            
            # ideal_end ê·¼ì²˜ì˜ ë¬´ìŒ êµ¬ê°„ ì°¾ê¸°
            for i in range(len(nonsilent_ranges) - 1):
                silence_start = nonsilent_ranges[i][1]
                silence_end = nonsilent_ranges[i + 1][0]
                
                # ë¬´ìŒ êµ¬ê°„ì´ ideal_end ê·¼ì²˜ì— ìˆìœ¼ë©´
                if abs(silence_start - ideal_end) < 2000:  # 2ì´ˆ ì´ë‚´
                    actual_end = silence_start
                    break
            
            # ì²­í¬ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ì¡°ì •
            if actual_end - current_start < min_chunk_ms and actual_end < duration_ms:
                actual_end = min(current_start + max_chunk_ms, duration_ms)
            
            # ì²­í¬ ì¶”ì¶œ (ì˜¤ë²„ë© í¬í•¨)
            chunk_end = min(actual_end + target_overlap_ms, duration_ms)
            chunk = audio[current_start:chunk_end]
            
            # ì €ì¥
            chunk_path = os.path.join(temp_dir, f"chunk_{chunk_index:04d}.wav")
            chunk.export(chunk_path, format="wav")
            chunks.append(chunk_path)
            
            print(f"  ì²­í¬ {chunk_index + 1}: {current_start/1000:.1f}ì´ˆ ~ {chunk_end/1000:.1f}ì´ˆ ({(chunk_end-current_start)/1000:.1f}ì´ˆ)")
            
            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ì  (ì˜¤ë²„ë© ì ìš©)
            current_start = actual_end - target_overlap_ms
            if current_start >= duration_ms - min_chunk_ms:
                break
            
            chunk_index += 1
        
        print(f"ğŸ“Š ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
        return chunks
    
    def split_audio(self, audio_path: str, chunk_seconds: int = None) -> List[str]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í•  (ë‹¨ìˆœ ë¶„í• , í´ë°±ìš©)
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            chunk_seconds: ì²­í¬ í¬ê¸° (ì´ˆ)
            
        Returns:
            ì²­í¬ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if not PYDUB_AVAILABLE:
            raise ImportError("pydubê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install pydub")
        
        chunk_seconds = chunk_seconds or self.MAX_CHUNK_SECONDS
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_file(audio_path)
        duration_ms = len(audio)
        chunk_ms = chunk_seconds * 1000
        overlap_ms = int(self.OVERLAP_SECONDS * 1000)  # 3ì´ˆ ì˜¤ë²„ë©
        
        chunks = []
        temp_dir = tempfile.mkdtemp()
        
        # ì²­í¬ ìƒì„±
        start_ms = 0
        chunk_index = 0
        
        print(f"ğŸ“Š ë‹¨ìˆœ ë¶„í• : ì´ {duration_ms/1000:.1f}ì´ˆ, {chunk_seconds}ì´ˆ ì²­í¬, {self.OVERLAP_SECONDS}ì´ˆ ì˜¤ë²„ë©")
        
        while start_ms < duration_ms:
            # ì²­í¬ ì¶”ì¶œ (ì˜¤ë²„ë© í¬í•¨í•˜ì—¬ ë” ê¸¸ê²Œ)
            end_ms = min(start_ms + chunk_ms + overlap_ms, duration_ms)
            chunk = audio[start_ms:end_ms]
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            chunk_path = os.path.join(temp_dir, f"chunk_{chunk_index:04d}.wav")
            chunk.export(chunk_path, format="wav")
            chunks.append(chunk_path)
            
            print(f"  ì²­í¬ {chunk_index + 1}: {start_ms/1000:.1f}ì´ˆ ~ {end_ms/1000:.1f}ì´ˆ")
            
            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ì  (ì˜¤ë²„ë© ì—†ì´)
            start_ms = start_ms + chunk_ms
            if start_ms >= duration_ms:
                break
                
            chunk_index += 1
        
        print(f"ğŸ“Š ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
        return chunks
    
    def recognize_long_audio(
        self, 
        audio_path: str, 
        language: str = "korean",
        progress_callback: Optional[Callable[[int, int, str], None]] = None,
        debug_mode: bool = False  # debug_mode ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
    ) -> Dict:
        """
        ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (ìë™ ë¶„í• , ì˜¤ë²„ë© ì¤‘ë³µ ì œê±°)
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± (current, total, status)
            
        Returns:
            {"success": bool, "text": str, "chunks": List[ChunkResult], "error": str}
        """
        if not PYDUB_AVAILABLE:
            # pydub ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì„œë“œë¡œ í´ë°± (20ì´ˆ ì´í•˜ë§Œ ê°€ëŠ¥)
            result = self.recognize(audio_path, language)
            return {
                **result,
                "chunks": [ChunkResult(0, result.get("text", ""), result["success"], result.get("error"))]
            }
        
        try:
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ í™•ì¸
            audio = AudioSegment.from_file(audio_path)
            duration_seconds = len(audio) / 1000
            
            print(f"ğŸ“Š ì˜¤ë””ì˜¤ ì •ë³´: {duration_seconds:.1f}ì´ˆ, {len(audio)}ms")
            
            # 20ì´ˆ ì´í•˜ë©´ ë°”ë¡œ ì²˜ë¦¬
            if duration_seconds <= self.MAX_CHUNK_SECONDS:
                result = self.recognize(audio_path, language)
                return {
                    **result,
                    "chunks": [ChunkResult(0, result.get("text", ""), result["success"], result.get("error"))],
                    "duration_seconds": duration_seconds
                }
            
            # ì²­í¬ ë¶„í•  (ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì‹œë„, ì‹¤íŒ¨ì‹œ ë‹¨ìˆœ ë¶„í• )
            if progress_callback:
                progress_callback(0, 100, "ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„í•  ì¤‘...")
            
            try:
                # ë¬´ìŒ êµ¬ê°„ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì‹œë„
                chunk_paths = self.split_audio_smart(audio_path)
                print("âœ… ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì‚¬ìš©")
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì‹¤íŒ¨, ë‹¨ìˆœ ë¶„í•  ì‚¬ìš©: {e}")
                # í´ë°±: ë‹¨ìˆœ ë¶„í• 
                chunk_paths = self.split_audio(audio_path)
            
            total_chunks = len(chunk_paths)
            
            # ì˜ˆìƒ ì‹œê°„ ê³„ì‚° (ë” ì •í™•í•˜ê²Œ)
            estimated_time = total_chunks * (2.5 + self.REQUEST_DELAY)  # API ì‘ë‹µ ì‹œê°„ í¬í•¨
            print(f"â±ï¸ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time:.0f}ì´ˆ ({total_chunks}ê°œ ì²­í¬)")
            
            # ì²­í¬ë³„ ì²˜ë¦¬
            chunks_results: List[ChunkResult] = []
            all_texts = []
            previous_text = ""  # ì´ì „ ì²­í¬ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ ì €ì¥ (ì¤‘ë³µ ì œê±°ìš©)
            
            for i, chunk_path in enumerate(chunk_paths):
                # ì§„í–‰ ìƒí™© ì•Œë¦¼
                if progress_callback:
                    percent = int((i / total_chunks) * 100)
                    remaining_time = (total_chunks - i) * (2.5 + self.REQUEST_DELAY)
                    progress_callback(percent, 100, f"ì²­í¬ {i+1}/{total_chunks} ì²˜ë¦¬ ì¤‘... (ë‚¨ì€ ì‹œê°„: ì•½ {int(remaining_time)}ì´ˆ)")
                
                # API í˜¸ì¶œ
                start_time = time.time()
                result = self.recognize(chunk_path, language)
                duration = time.time() - start_time
                
                # ê²°ê³¼ ì²˜ë¦¬ (ì¤‘ë³µ ì œê±° ê°œì„  - ìœ ì‚¬ë„ ê¸°ë°˜)
                current_text = result.get("text", "").strip()
                
                # ì˜¤ë²„ë© ì¤‘ë³µ ì œê±° (ìœ ì‚¬ë„ ì²´í¬ í¬í•¨)
                if i > 0 and previous_text and current_text:
                    # ì´ì „ ì²­í¬ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ê³¼ í˜„ì¬ ì²­í¬ì˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì¤‘ë³µ ì°¾ê¸°
                    max_overlap = min(100, len(previous_text) // 2, len(current_text) // 2)
                    
                    # 1. ì •í™•í•œ ì¼ì¹˜ ì°¾ê¸°
                    overlap_found = False
                    for check_len in range(max_overlap, 10, -1):
                        last_part = previous_text[-check_len:]
                        
                        # í˜„ì¬ í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ë¶€ë¶„ ì°¾ê¸°
                        idx = current_text.find(last_part)
                        if idx != -1 and idx < 50:  # ì‹œì‘ ë¶€ë¶„ ê·¼ì²˜ì—ì„œ ë°œê²¬
                            # ì¤‘ë³µ ì œê±°
                            current_text = current_text[idx + len(last_part):].strip()
                            if debug_mode:
                                print(f"ğŸ”„ ì²­í¬ {i+1}: {check_len}ì ì •í™•íˆ ì¼ì¹˜ - ì¤‘ë³µ ì œê±°")
                                print(f"   ì œê±°ëœ ë¶€ë¶„: '{last_part[:30]}...'")
                            overlap_found = True
                            break
                    
                    # 2. ìœ ì‚¬í•œ íŒ¨í„´ ì°¾ê¸° (ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
                    if not overlap_found:
                        # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¹„êµ
                        prev_words = previous_text.split()
                        curr_words = current_text.split()
                        
                        if len(prev_words) >= 3 and len(curr_words) >= 3:
                            # ë§ˆì§€ë§‰ ëª‡ ë‹¨ì–´ì™€ ì‹œì‘ ëª‡ ë‹¨ì–´ ë¹„êµ
                            for word_count in range(min(10, len(prev_words)//2), 2, -1):
                                last_words = prev_words[-word_count:]
                                
                                # í˜„ì¬ í…ìŠ¤íŠ¸ì˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ìœ ì‚¬í•œ íŒ¨í„´ ì°¾ê¸°
                                for start_idx in range(min(10, len(curr_words) - word_count + 1)):
                                    curr_segment = curr_words[start_idx:start_idx + word_count]
                                    
                                    # ìœ ì‚¬ë„ ê³„ì‚° (ë‹¨ì–´ ì¼ì¹˜ìœ¨)
                                    matches = sum(1 for a, b in zip(last_words, curr_segment) if a == b)
                                    similarity = matches / word_count
                                    
                                    if similarity >= 0.7:  # 70% ì´ìƒ ì¼ì¹˜
                                        # ì¤‘ë³µìœ¼ë¡œ íŒë‹¨í•˜ê³  ì œê±°
                                        remove_words = start_idx + word_count
                                        remaining_words = curr_words[remove_words:]
                                        current_text = ' '.join(remaining_words).strip()
                                        
                                        if debug_mode:
                                            print(f"ğŸ”„ ì²­í¬ {i+1}: {word_count}ë‹¨ì–´ ìœ ì‚¬ íŒ¨í„´ ë°œê²¬ - ì¤‘ë³µ ì œê±°")
                                            print(f"   ìœ ì‚¬ë„: {similarity:.1%}")
                                            print(f"   ì œê±°ëœ ë¶€ë¶„: '{' '.join(curr_words[:remove_words])}'")
                                        overlap_found = True
                                        break
                                
                                if overlap_found:
                                    break
                    
                    if not overlap_found and debug_mode:
                        print(f"ğŸ” ì²­í¬ {i+1}: ì¤‘ë³µ ì—†ìŒ")
                
                # ë¹ˆ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                if current_text:
                    # ê²°ê³¼ ì €ì¥
                    chunk_result = ChunkResult(
                        chunk_index=i,
                        text=current_text,
                        success=result["success"],
                        error=result.get("error"),
                        duration=duration
                    )
                    chunks_results.append(chunk_result)
                    
                    all_texts.append(current_text)
                    previous_text = result.get("text", "").strip()  # ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥ (ë‹¤ìŒ ë¹„êµìš©)
                else:
                    # ë¹ˆ ê²°ê³¼ (ì¤‘ë³µ ì œê±°ë¡œ ì¸í•´)
                    chunk_result = ChunkResult(
                        chunk_index=i,
                        text="[ì¤‘ë³µ ì œê±°ë¨]",
                        success=result["success"],
                        error=result.get("error"),
                        duration=duration
                    )
                    chunks_results.append(chunk_result)
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                try:
                    os.remove(chunk_path)
                except:
                    pass
                
                # ë‹¤ìŒ ìš”ì²­ ì „ ë”œë ˆì´ (ë§ˆì§€ë§‰ ì²­í¬ ì œì™¸)
                if i < total_chunks - 1:
                    time.sleep(self.REQUEST_DELAY)
            
            # ì™„ë£Œ ì•Œë¦¼
            if progress_callback:
                progress_callback(100, 100, "ì™„ë£Œ!")
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•© (ë¬¸ì¥ ë‹¨ìœ„ë¡œ ê°œì„ )
            if all_texts:
                # ê° ì²­í¬ í…ìŠ¤íŠ¸ ëì— ë§ˆì¹¨í‘œê°€ ì—†ìœ¼ë©´ ì¶”ê°€
                processed_texts = []
                for i, text in enumerate(all_texts):
                    text = text.strip()
                    if text and not text[-1] in '.!?':
                        text += '.'
                    processed_texts.append(text)
                
                # ê³µë°±ìœ¼ë¡œ ì—°ê²° (ë¬¸ì¥ ê°„ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ë¶„)
                combined_text = ' '.join(processed_texts)
                
                # ì—°ì†ëœ ê³µë°± ì œê±°
                combined_text = ' '.join(combined_text.split())
            else:
                combined_text = ""
            
            # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            success_count = sum(1 for c in chunks_results if c.success)
            
            return {
                "success": success_count > 0,
                "text": combined_text,
                "chunks": chunks_results,
                "total_chunks": total_chunks,
                "success_chunks": success_count,
                "duration_seconds": duration_seconds,
                "error": None if success_count == total_chunks else f"{total_chunks - success_count}ê°œ ì²­í¬ ì‹¤íŒ¨"
            }
            
        except Exception as e:
            return {
                "success": False,
                "text": "",
                "chunks": [],
                "error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            }


# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš©
    api_key = "YOUR_API_KEY"
    stt = ETRISpeechToText(api_key)
    result = stt.recognize("test.wav")
    
    if result["success"]:
        print(f"ì¸ì‹ ê²°ê³¼: {result['text']}")
    else:
        print(f"ì˜¤ë¥˜: {result['error']}")