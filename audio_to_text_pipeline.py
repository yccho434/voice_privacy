# audio_to_text_pipeline.py
"""
í†µí•© ìŒì„±â†’í…ìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸
librosa ì „ì²˜ë¦¬ + ETRI STT í†µí•©
UX ìµœì í™” ë²„ì „
"""

import os
import time
import json
import tempfile
from pathlib import Path
from typing import Optional, Dict, Callable, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta

# ëª¨ë“ˆ ì„í¬íŠ¸
from enhanced_audio_processor import EnhancedAudioProcessor
from improved_stt_processor import ImprovedSTTProcessor


@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    # API ì„¤ì •
    etri_api_key: str
    
    # ì²˜ë¦¬ ì˜µì…˜
    enhance_audio: bool = True
    aggressive_denoise: bool = False
    auto_detect_noise: bool = True
    parallel_stt: bool = True
    max_workers: int = 2
    enable_timestamps: bool = True  # íƒ€ì„ìŠ¤íƒ¬í”„ ì˜µì…˜ ì¶”ê°€
    
    # ì¶œë ¥ ì„¤ì •
    save_enhanced_audio: bool = False
    save_transcript: bool = True
    output_dir: str = "./output"


@dataclass
class PipelineResult:
    """íŒŒì´í”„ë¼ì¸ ê²°ê³¼"""
    success: bool
    transcript: str
    formatted_transcript: Optional[str]  # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í…ìŠ¤íŠ¸
    sentences: Optional[list[Dict]]  # ë¬¸ì¥ë³„ ì •ë³´
    
    # ì²˜ë¦¬ ì •ë³´
    original_audio_path: str
    enhanced_audio_path: Optional[str]
    transcript_path: Optional[str]
    
    # í†µê³„
    audio_duration: float
    processing_time: float
    audio_improvement: Dict
    stt_stats: Dict
    
    # íƒ€ì„ìŠ¤íƒ¬í”„
    timestamp: str
    

class AudioToTextPipeline:
    """í†µí•© ìŒì„±â†’í…ìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        self.audio_processor = EnhancedAudioProcessor(target_sr=16000)
        self.stt_processor = ImprovedSTTProcessor(config.etri_api_key)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        if config.save_enhanced_audio or config.save_transcript:
            Path(config.output_dir).mkdir(parents=True, exist_ok=True)
    
    def process(self,
                audio_path: str,
                progress_callback: Optional[Callable] = None) -> PipelineResult:
        """
        ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            audio_path: ì…ë ¥ ìŒì„± íŒŒì¼
            progress_callback: ì§„í–‰ ì½œë°± (step, percent, message, eta_seconds)
        
        Returns:
            PipelineResult
        """
        start_time = time.time()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì§„í–‰ ìƒí™© ì¶”ì 
        total_steps = 2 if self.config.enhance_audio else 1
        current_step = 0
        
        def update_progress(percent: int, message: str, eta: Optional[int] = None):
            """ë‚´ë¶€ ì§„í–‰ ì½œë°±"""
            if progress_callback:
                # ì „ì²´ ì§„í–‰ë¥  ê³„ì‚°
                step_weight = 100 / total_steps
                overall_percent = int(current_step * step_weight + percent * step_weight / 100)
                
                # ETA í¬ë§·íŒ…
                eta_str = None
                if eta:
                    eta_str = str(timedelta(seconds=eta))
                
                progress_callback(current_step + 1, overall_percent, message, eta_str)
        
        try:
            # 1ë‹¨ê³„: ìŒì„± í’ˆì§ˆ í–¥ìƒ (ì„ íƒì )
            audio_improvement = {}
            enhanced_audio_path = None
            
            if self.config.enhance_audio:
                current_step = 0
                update_progress(0, "ğŸµ ìŒì„± í’ˆì§ˆ í–¥ìƒ ì¤‘...")
                
                # í–¥ìƒ ì²˜ë¦¬
                if self.config.save_enhanced_audio:
                    output_name = f"enhanced_{timestamp}_{Path(audio_path).stem}.wav"
                    enhanced_audio_path = os.path.join(self.config.output_dir, output_name)
                else:
                    enhanced_audio_path = None
                
                audio_data, metrics = self.audio_processor.process(
                    audio_path,
                    enhanced_audio_path,
                    aggressive=self.config.aggressive_denoise,
                    auto_detect_noise=self.config.auto_detect_noise
                )
                
                audio_improvement = metrics.get('improvement', {})
                
                # ì„ì‹œ íŒŒì¼ ìƒì„± (STTìš©)
                if not enhanced_audio_path:
                    temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
                    import soundfile as sf
                    sf.write(temp_file.name, audio_data, 16000)
                    audio_for_stt = temp_file.name
                else:
                    audio_for_stt = enhanced_audio_path
                
                update_progress(100, "âœ… ìŒì„± í–¥ìƒ ì™„ë£Œ")
                
                # í’ˆì§ˆ ê°œì„  ìš”ì•½
                improvement_msg = f"ë…¸ì´ì¦ˆ {audio_improvement.get('noise_reduction', 0):.1f}% ê°ì†Œ"
                update_progress(100, improvement_msg)
                
            else:
                audio_for_stt = audio_path
            
            # 2ë‹¨ê³„: ìŒì„± ì¸ì‹
            current_step = 1 if self.config.enhance_audio else 0
            update_progress(0, "ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘...")
            
            # STT ì§„í–‰ ì½œë°± ë˜í¼
            def stt_progress(current: int, total: int, message: str, eta: Optional[int]):
                percent = int((current / total) * 100) if total > 0 else 0
                update_progress(percent, f"ğŸ¤ {message}", eta)
            
            # STT ì‹¤í–‰
            max_workers = self.config.max_workers if self.config.parallel_stt else 1
            stt_result = self.stt_processor.process(
                audio_for_stt,
                language="korean",
                max_workers=max_workers,
                progress_callback=stt_progress,
                enable_timestamps=self.config.enable_timestamps  # íƒ€ì„ìŠ¤íƒ¬í”„ ì˜µì…˜ ì „ë‹¬
            )
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if self.config.enhance_audio and not self.config.save_enhanced_audio:
                try:
                    os.remove(audio_for_stt)
                except:
                    pass
            
            # 3ë‹¨ê³„: ê²°ê³¼ ì €ì¥
            transcript_path = None
            formatted_transcript_path = None
            
            if self.config.save_transcript and stt_result.get('text'):
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ì €ì¥
                transcript_name = f"transcript_{timestamp}_{Path(audio_path).stem}.txt"
                transcript_path = os.path.join(self.config.output_dir, transcript_name)
                
                with open(transcript_path, 'w', encoding='utf-8') as f:
                    f.write(stt_result['text'])
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í…ìŠ¤íŠ¸ ì €ì¥
                if self.config.enable_timestamps and stt_result.get('formatted_text'):
                    formatted_name = f"transcript_{timestamp}_{Path(audio_path).stem}_timestamp.txt"
                    formatted_transcript_path = os.path.join(self.config.output_dir, formatted_name)
                    
                    with open(formatted_transcript_path, 'w', encoding='utf-8') as f:
                        f.write(stt_result['formatted_text'])
                
                # ë©”íƒ€ë°ì´í„°ë„ ì €ì¥
                meta_path = transcript_path.replace('.txt', '_meta.json')
                meta_data = {
                    'timestamp': timestamp,
                    'original_audio': audio_path,
                    'audio_improvement': audio_improvement,
                    'stt_stats': stt_result.get('stats', {}),
                    'processing_time': time.time() - start_time,
                    'sentences': stt_result.get('sentences', []) if self.config.enable_timestamps else []
                }
                
                with open(meta_path, 'w', encoding='utf-8') as f:
                    json.dump(meta_data, f, ensure_ascii=False, indent=2)
            
            # ì™„ë£Œ
            update_progress(100, "âœ… ì²˜ë¦¬ ì™„ë£Œ!")
            
            # ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚°
            try:
                import librosa
                y, sr = librosa.load(audio_path, sr=None)
                audio_duration = len(y) / sr
            except:
                audio_duration = 0
            
            # ê²°ê³¼ ìƒì„±
            return PipelineResult(
                success=stt_result.get('success', False),
                transcript=stt_result.get('text', ''),
                formatted_transcript=stt_result.get('formatted_text'),  # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
                sentences=stt_result.get('sentences'),  # ë¬¸ì¥ë³„ ì •ë³´
                original_audio_path=audio_path,
                enhanced_audio_path=enhanced_audio_path,
                transcript_path=transcript_path,
                audio_duration=audio_duration,
                processing_time=time.time() - start_time,
                audio_improvement=audio_improvement,
                stt_stats=stt_result.get('stats', {}),
                timestamp=timestamp
            )
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            
            return PipelineResult(
                success=False,
                transcript='',
                formatted_transcript=None,
                sentences=None,
                original_audio_path=audio_path,
                enhanced_audio_path=None,
                transcript_path=None,
                audio_duration=0,
                processing_time=time.time() - start_time,
                audio_improvement={},
                stt_stats={'error': str(e)},
                timestamp=timestamp
            )
    
    def process_batch(self,
                     audio_files: list,
                     progress_callback: Optional[Callable] = None) -> list:
        """
        ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ ì²˜ë¦¬
        
        Args:
            audio_files: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            progress_callback: ì§„í–‰ ì½œë°±
        
        Returns:
            PipelineResult ë¦¬ìŠ¤íŠ¸
        """
        results = []
        total_files = len(audio_files)
        
        for i, audio_path in enumerate(audio_files):
            # íŒŒì¼ë³„ ì§„í–‰ ì½œë°±
            def file_progress(step: int, percent: int, message: str, eta: str):
                if progress_callback:
                    overall_percent = int((i / total_files) * 100 + percent / total_files)
                    file_info = f"[{i+1}/{total_files}] {Path(audio_path).name}"
                    progress_callback(i+1, overall_percent, f"{file_info}: {message}", eta)
            
            # ì²˜ë¦¬
            result = self.process(audio_path, file_progress)
            results.append(result)
            
            # ì„±ê³µ/ì‹¤íŒ¨ ë¡œê·¸
            if result.success:
                print(f"âœ… {Path(audio_path).name}: {len(result.transcript)}ì ë³€í™˜ ì™„ë£Œ")
            else:
                print(f"âŒ {Path(audio_path).name}: ë³€í™˜ ì‹¤íŒ¨")
        
        return results


def process_audio_to_text(
    audio_path: str,
    etri_api_key: str,
    enhance_audio: bool = True,
    save_outputs: bool = True,
    progress_callback: Optional[Callable] = None
) -> Dict:
    """
    ê°„í¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        etri_api_key: ETRI API í‚¤
        enhance_audio: ìŒì„± í–¥ìƒ ì—¬ë¶€
        save_outputs: ê²°ê³¼ ì €ì¥ ì—¬ë¶€
        progress_callback: ì§„í–‰ ì½œë°±
    
    Returns:
        ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    config = PipelineConfig(
        etri_api_key=etri_api_key,
        enhance_audio=enhance_audio,
        save_enhanced_audio=save_outputs,
        save_transcript=save_outputs
    )
    
    pipeline = AudioToTextPipeline(config)
    result = pipeline.process(audio_path, progress_callback)
    
    return {
        'success': result.success,
        'transcript': result.transcript,
        'processing_time': result.processing_time,
        'audio_duration': result.audio_duration,
        'improvement': result.audio_improvement,
        'stats': result.stt_stats,
        'files': {
            'enhanced_audio': result.enhanced_audio_path,
            'transcript': result.transcript_path
        }
    }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import sys
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python audio_to_text_pipeline.py [ì˜¤ë””ì˜¤íŒŒì¼]")
        sys.exit(1)
    
    audio_file = sys.argv[1]
    api_key = os.getenv("ETRI_API_KEY")
    
    if not api_key:
        print("âŒ ETRI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”: export ETRI_API_KEY='your_key'")
        sys.exit(1)
    
    print(f"ğŸµ ì²˜ë¦¬ ì‹œì‘: {audio_file}")
    
    # ì§„í–‰ í‘œì‹œ
    def show_progress(step, percent, message, eta):
        bar_length = 30
        filled = int(bar_length * percent / 100)
        bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
        eta_str = f" ETA: {eta}" if eta else ""
        print(f"\r[{bar}] {percent:3d}% | {message}{eta_str}", end="", flush=True)
    
    # ì²˜ë¦¬ ì‹¤í–‰
    result = process_audio_to_text(
        audio_file,
        api_key,
        enhance_audio=True,
        save_outputs=True,
        progress_callback=show_progress
    )
    
    print("\n")
    
    if result['success']:
        print("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"- ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.1f}ì´ˆ")
        print(f"- ì˜¤ë””ì˜¤ ê¸¸ì´: {result['audio_duration']:.1f}ì´ˆ")
        print(f"- í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result['transcript'])}ì")
        print(f"- ë…¸ì´ì¦ˆ ê°ì†Œ: {result['improvement'].get('noise_reduction', 0):.1f}%")
        print(f"\nğŸ“ ë³€í™˜ í…ìŠ¤íŠ¸:\n{result['transcript'][:500]}...")
    else:
        print("âŒ ì²˜ë¦¬ ì‹¤íŒ¨")
        print(result.get('stats', {}).get('error', 'Unknown error'))