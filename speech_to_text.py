# speech_to_text.py
"""
ETRI ìŒì„±ì¸ì‹ API ëª¨ë“ˆ
ê¸´ ìŒì„± íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì²­í¬ ë¶„í•  + ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
"""

import json
import base64
import urllib3
import time
import tempfile
import os
import sys
from typing import Optional, Dict, List, Callable, Tuple
from pathlib import Path
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed

# SSL ê²½ê³  ë¹„í™œì„±í™”
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# FFmpeg ìë™ ì„¤ì •
try:
    import imageio_ffmpeg
    ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()
    
    # pydubì— FFmpeg ê²½ë¡œ ì„¤ì •
    from pydub.utils import which
    from pydub import AudioSegment
    
    if not which("ffmpeg"):
        AudioSegment.converter = ffmpeg_path
        AudioSegment.ffmpeg = ffmpeg_path
        AudioSegment.ffprobe = ffmpeg_path.replace("ffmpeg", "ffprobe")
        print(f"âœ… FFmpeg ìë™ ì„¤ì • ì™„ë£Œ: {ffmpeg_path}")
    
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("âš ï¸ pydub ë˜ëŠ” imageio-ffmpeg ì„¤ì¹˜ í•„ìš”")

# Windows Chocolatey FFmpeg ê²½ë¡œ ì¶”ê°€ (í´ë°±)
if sys.platform == "win32" and PYDUB_AVAILABLE:
    choco_path = r"C:\ProgramData\chocolatey\bin"
    if os.path.exists(os.path.join(choco_path, "ffmpeg.exe")):
        os.environ["PATH"] = choco_path + os.pathsep + os.environ.get("PATH", "")


@dataclass
class ChunkResult:
    """ì²­í¬ ì²˜ë¦¬ ê²°ê³¼"""
    chunk_index: int
    text: str
    success: bool
    error: Optional[str] = None
    duration: float = 0.0


class ETRISpeechToText:
    """ETRI ìŒì„±ì¸ì‹ API í´ë¼ì´ì–¸íŠ¸ (ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›)"""
    
    API_URL = "http://epretx.etri.re.kr:8000/api/WiseASR_Recognition"
    MAX_CHUNK_SECONDS = 15  # ì²­í¬ í¬ê¸°
    OVERLAP_SECONDS = 3.0    # ì˜¤ë²„ë©
    REQUEST_DELAY = 1.0      # ìˆœì°¨ ì²˜ë¦¬ì‹œ ìš”ì²­ ê°„ ë”œë ˆì´
    PARALLEL_BATCH_DELAY = 0.3  # ë³‘ë ¬ ì²˜ë¦¬ì‹œ ë°°ì¹˜ ê°„ ë”œë ˆì´
    
    def __init__(self, access_key: str):
        """
        Args:
            access_key: ETRI API ì ‘ê·¼ í‚¤
        """
        self.access_key = access_key
        self.http = urllib3.PoolManager()
    
    def recognize(self, audio_file_path: str, language: str = "korean") -> Dict:
        """
        ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ê¸°ë³¸ ë©”ì„œë“œ)
        
        Args:
            audio_file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ (korean, english, japanese, chinese ë“±)
            
        Returns:
            {"success": bool, "text": str, "error": str}
        """
        try:
            # íŒŒì¼ ì½ê¸° ë° Base64 ì¸ì½”ë”©
            with open(audio_file_path, "rb") as f:
                audio_contents = base64.b64encode(f.read()).decode("utf8")
            
            # API ìš”ì²­ êµ¬ì„±
            request_json = {
                "argument": {
                    "language_code": language,
                    "audio": audio_contents
                }
            }
            
            # API í˜¸ì¶œ
            response = self.http.request(
                "POST",
                self.API_URL,
                headers={
                    "Content-Type": "application/json; charset=UTF-8",
                    "Authorization": self.access_key
                },
                body=json.dumps(request_json)
            )
            
            if response.status == 200:
                result = json.loads(response.data.decode("utf-8"))
                
                if result.get("result", -1) == 0:
                    # ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    return_obj = result.get("return_object", {})
                    recognized_text = return_obj.get("recognized", "")
                    
                    # recognized í•„ë“œê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ í•„ë“œ í™•ì¸
                    if not recognized_text:
                        recognized_text = return_obj.get("result", "")
                        if not recognized_text:
                            recognized_text = return_obj.get("text", "")
                    
                    return {
                        "success": True,
                        "text": recognized_text,
                        "error": None
                    }
                else:
                    error_msg = f"API Error Code: {result.get('result')}"
                    if result.get('reason'):
                        error_msg += f" - Reason: {result.get('reason')}"
                    
                    return {
                        "success": False,
                        "text": "",
                        "error": error_msg
                    }
            else:
                return {
                    "success": False,
                    "text": "",
                    "error": f"HTTP Error {response.status}"
                }
                
        except FileNotFoundError:
            return {
                "success": False,
                "text": "",
                "error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}"
            }
        except Exception as e:
            return {
                "success": False,
                "text": "",
                "error": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def split_audio_smart(self, audio_path: str) -> List[str]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ë¶„í•  (ë¬´ìŒ êµ¬ê°„ í™œìš©)
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì²­í¬ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if not PYDUB_AVAILABLE:
            raise ImportError("pydubê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install pydub")
        
        from pydub.silence import detect_nonsilent
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_file(audio_path)
        duration_ms = len(audio)
        
        # ë¬´ìŒì´ ì•„ë‹Œ êµ¬ê°„ ê°ì§€
        nonsilent_ranges = detect_nonsilent(
            audio,
            min_silence_len=300,  # 0.3ì´ˆ ì´ìƒ ë¬´ìŒ
            silence_thresh=-40,    # dB
            seek_step=10
        )
        
        chunks = []
        temp_dir = tempfile.mkdtemp()
        chunk_index = 0
        
        # ìµœëŒ€ 15ì´ˆ, ìµœì†Œ 5ì´ˆ ì²­í¬
        max_chunk_ms = 15000
        min_chunk_ms = 5000
        target_overlap_ms = 3000  # 3ì´ˆ ì˜¤ë²„ë©
        
        current_start = 0
        
        print(f"ğŸ“Š ìŠ¤ë§ˆíŠ¸ ë¶„í• : ì´ {duration_ms/1000:.1f}ì´ˆ")
        
        while current_start < duration_ms:
            # ì´ìƒì ì¸ ë ì§€ì 
            ideal_end = min(current_start + max_chunk_ms, duration_ms)
            
            # ì‹¤ì œ ë ì§€ì  ì°¾ê¸° (ë¬´ìŒ êµ¬ê°„ ì°¾ê¸°)
            actual_end = ideal_end
            
            # ideal_end ê·¼ì²˜ì˜ ë¬´ìŒ êµ¬ê°„ ì°¾ê¸°
            for i in range(len(nonsilent_ranges) - 1):
                silence_start = nonsilent_ranges[i][1]
                silence_end = nonsilent_ranges[i + 1][0]
                
                # ë¬´ìŒ êµ¬ê°„ì´ ideal_end ê·¼ì²˜ì— ìˆìœ¼ë©´
                if abs(silence_start - ideal_end) < 2000:  # 2ì´ˆ ì´ë‚´
                    actual_end = silence_start
                    break
            
            # ì²­í¬ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ì¡°ì •
            if actual_end - current_start < min_chunk_ms and actual_end < duration_ms:
                actual_end = min(current_start + max_chunk_ms, duration_ms)
            
            # ì²­í¬ ì¶”ì¶œ (ì˜¤ë²„ë© í¬í•¨)
            chunk_end = min(actual_end + target_overlap_ms, duration_ms)
            chunk = audio[current_start:chunk_end]
            
            # ì €ì¥
            chunk_path = os.path.join(temp_dir, f"chunk_{chunk_index:04d}.wav")
            chunk.export(chunk_path, format="wav")
            chunks.append(chunk_path)
            
            print(f"  ì²­í¬ {chunk_index + 1}: {current_start/1000:.1f}ì´ˆ ~ {chunk_end/1000:.1f}ì´ˆ ({(chunk_end-current_start)/1000:.1f}ì´ˆ)")
            
            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ì  (ì˜¤ë²„ë© ì ìš©)
            current_start = actual_end - target_overlap_ms
            if current_start >= duration_ms - min_chunk_ms:
                break
            
            chunk_index += 1
        
        print(f"ğŸ“Š ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
        return chunks
    
    def split_audio(self, audio_path: str, chunk_seconds: int = None) -> List[str]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í•  (ë‹¨ìˆœ ë¶„í• , í´ë°±ìš©)
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            chunk_seconds: ì²­í¬ í¬ê¸° (ì´ˆ)
            
        Returns:
            ì²­í¬ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if not PYDUB_AVAILABLE:
            raise ImportError("pydubê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install pydub")
        
        chunk_seconds = chunk_seconds or self.MAX_CHUNK_SECONDS
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_file(audio_path)
        duration_ms = len(audio)
        chunk_ms = chunk_seconds * 1000
        overlap_ms = int(self.OVERLAP_SECONDS * 1000)  # 3ì´ˆ ì˜¤ë²„ë©
        
        chunks = []
        temp_dir = tempfile.mkdtemp()
        
        # ì²­í¬ ìƒì„±
        start_ms = 0
        chunk_index = 0
        
        print(f"ğŸ“Š ë‹¨ìˆœ ë¶„í• : ì´ {duration_ms/1000:.1f}ì´ˆ, {chunk_seconds}ì´ˆ ì²­í¬, {self.OVERLAP_SECONDS}ì´ˆ ì˜¤ë²„ë©")
        
        while start_ms < duration_ms:
            # ì²­í¬ ì¶”ì¶œ (ì˜¤ë²„ë© í¬í•¨í•˜ì—¬ ë” ê¸¸ê²Œ)
            end_ms = min(start_ms + chunk_ms + overlap_ms, duration_ms)
            chunk = audio[start_ms:end_ms]
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            chunk_path = os.path.join(temp_dir, f"chunk_{chunk_index:04d}.wav")
            chunk.export(chunk_path, format="wav")
            chunks.append(chunk_path)
            
            print(f"  ì²­í¬ {chunk_index + 1}: {start_ms/1000:.1f}ì´ˆ ~ {end_ms/1000:.1f}ì´ˆ")
            
            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ì  (ì˜¤ë²„ë© ì—†ì´)
            start_ms = start_ms + chunk_ms
            if start_ms >= duration_ms:
                break
                
            chunk_index += 1
        
        print(f"ğŸ“Š ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
        return chunks
    
    def _process_sequential(self, chunk_paths: List[str], language: str, 
                          progress_callback: Optional[Callable] = None) -> Tuple[List[ChunkResult], List[str]]:
        """
        ìˆœì°¨ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
        
        Returns:
            (ì²­í¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸)
        """
        chunks_results = []
        all_texts = []
        previous_text = ""
        
        for i, chunk_path in enumerate(chunk_paths):
            # ì§„í–‰ ìƒí™© ì•Œë¦¼
            if progress_callback:
                percent = int((i / len(chunk_paths)) * 100)
                progress_callback(percent, 100, f"ì²­í¬ {i+1}/{len(chunk_paths)} ì²˜ë¦¬ ì¤‘...")
            
            # API í˜¸ì¶œ
            start_time = time.time()
            result = self.recognize(chunk_path, language)
            duration = time.time() - start_time
            
            # ê²°ê³¼ ì²˜ë¦¬ (ì¤‘ë³µ ì œê±°)
            current_text = result.get("text", "").strip()
            
            # ì˜¤ë²„ë© ì¤‘ë³µ ì œê±°
            if i > 0 and previous_text and current_text:
                max_overlap = min(100, len(previous_text) // 2, len(current_text) // 2)
                
                for check_len in range(max_overlap, 10, -1):
                    last_part = previous_text[-check_len:]
                    idx = current_text.find(last_part)
                    if idx != -1 and idx < 50:
                        current_text = current_text[idx + len(last_part):].strip()
                        break
            
            if current_text:
                chunk_result = ChunkResult(
                    chunk_index=i,
                    text=current_text,
                    success=result["success"],
                    error=result.get("error"),
                    duration=duration
                )
                chunks_results.append(chunk_result)
                all_texts.append(current_text)
                previous_text = result.get("text", "").strip()
            
            # ë‹¤ìŒ ìš”ì²­ ì „ ë”œë ˆì´
            if i < len(chunk_paths) - 1:
                time.sleep(self.REQUEST_DELAY)
        
        return chunks_results, all_texts
    
    def _process_parallel(self, chunk_paths: List[str], language: str, max_workers: int,
                         progress_callback: Optional[Callable] = None) -> Tuple[List[ChunkResult], List[str]]:
        """
        ë³‘ë ¬ ì²˜ë¦¬ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        
        Args:
            max_workers: ë™ì‹œ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (1 ë˜ëŠ” 2)
            
        Returns:
            (ì²­í¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸)
        """
        chunks_results = []
        all_texts = []
        total_chunks = len(chunk_paths)
        
        print(f"âš¡ ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ ({max_workers} ì›Œì»¤) - {total_chunks}ê°œ ì²­í¬")
        
        # ì²« ì²­í¬ëŠ” í…ŒìŠ¤íŠ¸ìš© ìˆœì°¨ ì²˜ë¦¬
        if progress_callback:
            progress_callback(0, total_chunks, "ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        first_result = self.recognize(chunk_paths[0], language)
        if not first_result["success"]:
            print("âš ï¸ ì²« ì²­í¬ ì‹¤íŒ¨, ìˆœì°¨ ëª¨ë“œë¡œ ì „í™˜")
            return self._process_sequential(chunk_paths, language, progress_callback)
        
        chunks_results.append(ChunkResult(0, first_result.get("text", ""), True))
        all_texts.append(first_result.get("text", ""))
        
        # ë‚˜ë¨¸ì§€ ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬
        remaining_chunks = chunk_paths[1:]
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            
            # ì‘ì—… ì œì¶œ
            for i, chunk_path in enumerate(remaining_chunks, 1):
                # ì›Œì»¤ ìˆ˜ì— ë”°ë¥¸ ë”œë ˆì´ ì¡°ì •
                if max_workers == 2 and i % 2 == 0:
                    time.sleep(self.PARALLEL_BATCH_DELAY)  # 2ê°œë§ˆë‹¤ ë”œë ˆì´
                
                future = executor.submit(self.recognize, chunk_path, language)
                futures.append((i, future, chunk_path))
                
                if progress_callback:
                    progress_callback(i, total_chunks, f"ì²­í¬ {i+1}/{total_chunks} ì œì¶œ ì¤‘...")
            
            # ê²°ê³¼ ìˆ˜ì§‘
            print("â³ ê²°ê³¼ ëŒ€ê¸° ì¤‘...")
            for chunk_index, future, chunk_path in futures:
                try:
                    result = future.result(timeout=30)
                    
                    if result["success"]:
                        chunks_results.append(ChunkResult(
                            chunk_index,
                            result.get("text", ""),
                            True
                        ))
                        all_texts.append(result.get("text", ""))
                        print(f"  âœ… ì²­í¬ {chunk_index+1} ì™„ë£Œ")
                    else:
                        # ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„
                        print(f"  âš ï¸ ì²­í¬ {chunk_index+1} ì‹¤íŒ¨, ì¬ì‹œë„...")
                        time.sleep(2)
                        retry_result = self.recognize(chunk_path, language)
                        
                        if retry_result["success"]:
                            all_texts.append(retry_result.get("text", ""))
                            print(f"  âœ… ì²­í¬ {chunk_index+1} ì¬ì‹œë„ ì„±ê³µ")
                        else:
                            chunks_results.append(ChunkResult(
                                chunk_index,
                                "",
                                False,
                                retry_result.get("error")
                            ))
                            print(f"  âŒ ì²­í¬ {chunk_index+1} ìµœì¢… ì‹¤íŒ¨")
                    
                except Exception as e:
                    print(f"âŒ ì²­í¬ {chunk_index+1} ì˜ˆì™¸: {e}")
                    chunks_results.append(ChunkResult(
                        chunk_index,
                        "",
                        False,
                        str(e)
                    ))
                
                if progress_callback:
                    percent = int((chunk_index / total_chunks) * 100)
                    progress_callback(percent, 100, f"ì²­í¬ {chunk_index+1}/{total_chunks} ì²˜ë¦¬ ì™„ë£Œ")
        
        return chunks_results, all_texts
    
    def recognize_long_audio(
        self, 
        audio_path: str, 
        language: str = "korean",
        progress_callback: Optional[Callable[[int, int, str], None]] = None,
        debug_mode: bool = False,
        max_workers: int = 1  # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (1=ìˆœì°¨, 2=ë³‘ë ¬)
    ) -> Dict:
        """
        ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬ ì˜µì…˜ í¬í•¨)
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± (current, total, status)
            debug_mode: ë””ë²„ê·¸ ëª¨ë“œ
            max_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (1=ìˆœì°¨, 2=ë³‘ë ¬)
            
        Returns:
            {"success": bool, "text": str, "chunks": List[ChunkResult], "error": str, "processing_mode": str}
        """
        if not PYDUB_AVAILABLE:
            # pydub ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì„œë“œë¡œ í´ë°±
            result = self.recognize(audio_path, language)
            return {
                **result,
                "chunks": [ChunkResult(0, result.get("text", ""), result["success"], result.get("error"))],
                "processing_mode": "single"
            }
        
        try:
            start_total_time = time.time()
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ í™•ì¸
            audio = AudioSegment.from_file(audio_path)
            duration_seconds = len(audio) / 1000
            
            print(f"ğŸ“Š ì˜¤ë””ì˜¤ ì •ë³´: {duration_seconds:.1f}ì´ˆ, {len(audio)}ms")
            
            # 20ì´ˆ ì´í•˜ë©´ ë°”ë¡œ ì²˜ë¦¬
            if duration_seconds <= self.MAX_CHUNK_SECONDS:
                result = self.recognize(audio_path, language)
                return {
                    **result,
                    "chunks": [ChunkResult(0, result.get("text", ""), result["success"], result.get("error"))],
                    "duration_seconds": duration_seconds,
                    "processing_mode": "single"
                }
            
            # ì²­í¬ ë¶„í• 
            if progress_callback:
                progress_callback(0, 100, "ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„í•  ì¤‘...")
            
            try:
                chunk_paths = self.split_audio_smart(audio_path)
                print("âœ… ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì‚¬ìš©")
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì‹¤íŒ¨, ë‹¨ìˆœ ë¶„í•  ì‚¬ìš©: {e}")
                chunk_paths = self.split_audio(audio_path)
            
            total_chunks = len(chunk_paths)
            
            # ì²˜ë¦¬ ëª¨ë“œ ê²°ì •
            if max_workers == 1 or total_chunks <= 3:
                # ìˆœì°¨ ì²˜ë¦¬
                processing_mode = "sequential"
                chunks_results, all_texts = self._process_sequential(
                    chunk_paths, language, progress_callback
                )
            else:
                # ë³‘ë ¬ ì²˜ë¦¬
                processing_mode = f"parallel_{max_workers}_workers"
                chunks_results, all_texts = self._process_parallel(
                    chunk_paths, language, max_workers, progress_callback
                )
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for chunk_path in chunk_paths:
                try:
                    os.remove(chunk_path)
                except:
                    pass
            
            # ì™„ë£Œ ì•Œë¦¼
            if progress_callback:
                progress_callback(100, 100, "ì™„ë£Œ!")
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
            if all_texts:
                processed_texts = []
                for text in all_texts:
                    text = text.strip()
                    if text and not text[-1] in '.!?':
                        text += '.'
                    processed_texts.append(text)
                
                combined_text = ' '.join(processed_texts)
                combined_text = ' '.join(combined_text.split())
            else:
                combined_text = ""
            
            # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            success_count = sum(1 for c in chunks_results if c.success)
            total_time = time.time() - start_total_time
            
            return {
                "success": success_count > 0,
                "text": combined_text,
                "chunks": chunks_results,
                "total_chunks": total_chunks,
                "success_chunks": success_count,
                "duration_seconds": duration_seconds,
                "processing_time": total_time,
                "processing_mode": processing_mode,
                "error": None if success_count == total_chunks else f"{total_chunks - success_count}ê°œ ì²­í¬ ì‹¤íŒ¨"
            }
            
        except Exception as e:
            return {
                "success": False,
                "text": "",
                "chunks": [],
                "error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                "processing_mode": "error"
            }


# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python speech_to_text.py [ì˜¤ë””ì˜¤íŒŒì¼] [ì›Œì»¤ìˆ˜(1ë˜ëŠ”2)]")
        print("ì˜ˆì‹œ: python speech_to_text.py test.mp3 2")
        sys.exit(1)
    
    api_key = os.getenv("ETRI_API_KEY", "YOUR_API_KEY")
    audio_file = sys.argv[1]
    max_workers = int(sys.argv[2]) if len(sys.argv) > 2 else 1
    
    stt = ETRISpeechToText(api_key)
    result = stt.recognize_long_audio(audio_file, max_workers=max_workers)
    
    if result["success"]:
        print(f"\nâœ… ì¸ì‹ ì„±ê³µ!")
        print(f"ì²˜ë¦¬ ëª¨ë“œ: {result.get('processing_mode')}")
        print(f"ì²˜ë¦¬ ì‹œê°„: {result.get('processing_time', 0):.1f}ì´ˆ")
        print(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result['text'])}ì")
        print(f"\nì¸ì‹ ê²°ê³¼:\n{result['text'][:500]}...")  # ì²˜ìŒ 500ìë§Œ ì¶œë ¥
    else:
        print(f"âŒ ì˜¤ë¥˜: {result['error']}")