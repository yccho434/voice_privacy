# improved_stt_processor.py
"""
ê°œì„ ëœ ETRI STT ì²˜ë¦¬ ëª¨ë“ˆ (íƒ€ì„ìŠ¤íƒ¬í”„ í†µí•© ë²„ì „)
- ë¬¸ì¥ ë‹¨ìœ„ ìŠ¤ë§ˆíŠ¸ ì²­í‚¹ìœ¼ë¡œ ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„
- 20ì´ˆ ì œí•œ ë‚´ ìµœì í™”
- ì•ˆì •ì ì¸ ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 2ì›Œì»¤)
"""

import json
import base64
import urllib3
import time
import tempfile
import os
from typing import Optional, Dict, List, Callable, Tuple
from pathlib import Path
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
import numpy as np

# SSL ê²½ê³  ë¹„í™œì„±í™”
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# pydub ìë™ ì„¤ì •
try:
    from pydub import AudioSegment
    from pydub.silence import detect_nonsilent, detect_silence, split_on_silence
    import imageio_ffmpeg
    
    ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()
    AudioSegment.converter = ffmpeg_path
    AudioSegment.ffmpeg = ffmpeg_path
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("âš ï¸ pydub ì„¤ì¹˜ í•„ìš”")


@dataclass
class ChunkInfo:
    """ì²­í¬ ì •ë³´"""
    index: int
    path: str
    start_ms: int
    end_ms: int
    duration_ms: int
    has_speech: bool
    overlap_with_next: int = 0
    is_merged: bool = False
    merged_indices: List[int] = None
    
@dataclass
class ProcessResult:
    """ì²˜ë¦¬ ê²°ê³¼"""
    success: bool
    text: str
    chunk_index: int
    duration: float
    retry_count: int = 0
    error: Optional[str] = None
    start_time: float = 0.0  # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
    end_time: float = 0.0


class ImprovedSTTProcessor:
    """ê°œì„ ëœ STT ì²˜ë¦¬ê¸°"""
    
    API_URL = "http://epretx.etri.re.kr:8000/api/WiseASR_Recognition"
    MAX_DURATION_MS = 20000  # 20ì´ˆ (API ì œí•œ)
    MIN_CHUNK_MS = 3000      # ìµœì†Œ 3ì´ˆ
    OPTIMAL_CHUNK_MS = 15000 # ìµœì  15ì´ˆ
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.http = urllib3.PoolManager()
        self.processing_stats = {
            'total_chunks': 0,
            'success_chunks': 0,
            'failed_chunks': 0,
            'retry_count': 0,
            'total_duration': 0
        }
    
    def process(self,
                audio_path: str,
                language: str = "korean",
                max_workers: int = 2,
                progress_callback: Optional[Callable] = None,
                enable_timestamps: bool = True) -> Dict:
        """
        ë©”ì¸ STT ì²˜ë¦¬ í•¨ìˆ˜ (íƒ€ì„ìŠ¤íƒ¬í”„ ì˜µì…˜ ì¶”ê°€)
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ
            max_workers: ë³‘ë ¬ ì›Œì»¤ ìˆ˜ (1-2)
            progress_callback: ì§„í–‰ ì½œë°±(current, total, message, eta)
            enable_timestamps: íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ì—¬ë¶€
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        # 1. ì˜¤ë””ì˜¤ ë¶„ì„ ë° ì²­í¬ ìƒì„±
        if progress_callback:
            progress_callback(0, 100, "ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...", None)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ëª¨ë“œë©´ ë¬¸ì¥ ë‹¨ìœ„ ì²­í‚¹
        if enable_timestamps:
            chunks = self._create_sentence_chunks(audio_path)
        else:
            chunks = self._create_smart_chunks(audio_path)
            
        if not chunks:
            return {
                'success': False,
                'text': '',
                'error': 'ì²­í¬ ìƒì„± ì‹¤íŒ¨'
            }
        
        self.processing_stats['total_chunks'] = len(chunks)
        
        # 2. ì²˜ë¦¬ ëª¨ë“œ ê²°ì •
        if len(chunks) == 1:
            mode = "single"
        elif max_workers == 1 or len(chunks) <= 2:
            mode = "sequential"
        else:
            mode = "parallel"
        
        # 3. ì²­í¬ ì²˜ë¦¬
        if mode == "single":
            results = self._process_single(chunks[0], language, progress_callback)
        elif mode == "sequential":
            results = self._process_sequential(chunks, language, progress_callback)
        else:
            results = self._process_parallel(chunks, language, max_workers, progress_callback)
        
        # 4. íƒ€ì„ìŠ¤íƒ¬í”„ ì²˜ë¦¬
        if enable_timestamps:
            sentences = self._organize_with_timestamps(results, chunks)
            final_text = self._extract_plain_text(sentences)
            formatted_text = self._format_with_timestamps(sentences)
        else:
            # ê¸°ì¡´ ë°©ì‹
            final_text = self._merge_results(results)
            formatted_text = None
            sentences = None
        
        # 5. í†µê³„ ë° ê²°ê³¼ ìƒì„±
        total_time = time.time() - start_time
        success_rate = self.processing_stats['success_chunks'] / self.processing_stats['total_chunks']
        
        # ì²­í¬ ì •ë¦¬
        for chunk in chunks:
            try:
                os.remove(chunk.path)
            except:
                pass
        
        result_dict = {
            'success': success_rate > 0.5,
            'text': final_text,
            'mode': mode,
            'stats': {
                **self.processing_stats,
                'success_rate': success_rate,
                'processing_time': total_time
            },
            'chunks_detail': [
                {
                    'index': r.chunk_index,
                    'success': r.success,
                    'text_length': len(r.text) if r.success else 0,
                    'retry_count': r.retry_count
                } for r in results
            ]
        }
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ ì¶”ê°€
        if enable_timestamps:
            result_dict['formatted_text'] = formatted_text
            result_dict['sentences'] = sentences
        
        return result_dict
    
    def _create_sentence_chunks(self, audio_path: str) -> List[ChunkInfo]:
        """ë¬¸ì¥ ë‹¨ìœ„ ìŠ¤ë§ˆíŠ¸ ì²­í‚¹ (ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„)"""
        if not PYDUB_AVAILABLE:
            return []
        
        from pydub.silence import detect_nonsilent
        
        audio = AudioSegment.from_file(audio_path)
        duration_ms = len(audio)
        
        # ë¬´ìŒì´ ì•„ë‹Œ êµ¬ê°„ ê°ì§€ (ì‹¤ì œ ë°œí™” ìœ„ì¹˜)
        nonsilent_ranges = detect_nonsilent(
            audio,
            min_silence_len=300,  # 0.3ì´ˆ ì´ìƒ ë¬´ìŒ
            silence_thresh=-35,   # -35dB
            seek_step=10
        )
        
        if not nonsilent_ranges:
            # ë¬´ìŒë§Œ ìˆëŠ” ê²½ìš°
            return []
        
        print(f"ğŸ“Š ë°œí™” êµ¬ê°„ ê°ì§€: {len(nonsilent_ranges)}ê°œ")
        
        # ì²­í¬ ì •ë³´ ìƒì„±
        temp_dir = tempfile.mkdtemp()
        chunks = []
        
        # ë°œí™” êµ¬ê°„ì„ ì²­í¬ë¡œ ë³€í™˜ (ì‹¤ì œ ì‹œê°„ ìœ„ì¹˜ ë³´ì¡´)
        optimized_chunks = []
        i = 0
        
        while i < len(nonsilent_ranges):
            start_ms, end_ms = nonsilent_ranges[i]
            chunk_duration_ms = end_ms - start_ms
            
            # ë„ˆë¬´ ì§§ì€ ë°œí™”: ë‹¤ìŒê³¼ ë³‘í•© (3ì´ˆ ë¯¸ë§Œ)
            if chunk_duration_ms < 3000 and i < len(nonsilent_ranges) - 1:
                # ë³‘í•©í•  ì²­í¬ë“¤ ìˆ˜ì§‘
                merged_start = start_ms
                merged_end = end_ms
                merged_indices = [i]
                
                j = i + 1
                while j < len(nonsilent_ranges):
                    next_start, next_end = nonsilent_ranges[j]
                    
                    # ë‹¤ìŒ ë°œí™”ê¹Œì§€ì˜ ê°„ê²© í™•ì¸
                    gap_ms = next_start - merged_end
                    
                    # ê°„ê²©ì´ 2ì´ˆ ì´ë‚´ì´ê³  ì´ ê¸¸ì´ê°€ 20ì´ˆ ë¯¸ë§Œì´ë©´ ë³‘í•©
                    if gap_ms < 2000 and (next_end - merged_start) < 20000:
                        merged_end = next_end
                        merged_indices.append(j)
                        j += 1
                        
                        # ì¶©ë¶„í•œ ê¸¸ì´ê°€ ë˜ë©´ ì¤‘ë‹¨
                        if merged_end - merged_start >= 8000:  # 8ì´ˆ ì´ìƒ
                            break
                    else:
                        break
                
                # ë³‘í•©ëœ ì²­í¬ ìƒì„± (ì‹¤ì œ ìœ„ì¹˜ ë³´ì¡´)
                optimized_chunks.append({
                    'start_ms': merged_start,  # ì‹¤ì œ ì‹œì‘ ìœ„ì¹˜
                    'end_ms': merged_end,      # ì‹¤ì œ ë ìœ„ì¹˜
                    'is_merged': len(merged_indices) > 1,
                    'merged_indices': merged_indices if len(merged_indices) > 1 else None,
                    'original_ranges': [nonsilent_ranges[idx] for idx in merged_indices]
                })
                i = j
                
            # ë„ˆë¬´ ê¸´ ë°œí™”: ë¶„í•  (20ì´ˆ ì´ˆê³¼)
            elif chunk_duration_ms > 20000:
                # 15ì´ˆ ë‹¨ìœ„ë¡œ ë¶„í• 
                chunk_start = start_ms
                while chunk_start < end_ms:
                    chunk_end = min(chunk_start + 15000, end_ms)
                    
                    optimized_chunks.append({
                        'start_ms': chunk_start,  # ì‹¤ì œ ì‹œì‘ ìœ„ì¹˜
                        'end_ms': chunk_end,      # ì‹¤ì œ ë ìœ„ì¹˜
                        'is_merged': False,
                        'merged_indices': None,
                        'original_ranges': [(chunk_start, chunk_end)]
                    })
                    
                    chunk_start = chunk_end
                i += 1
                
            # ì ì ˆí•œ ê¸¸ì´: ê·¸ëŒ€ë¡œ ì‚¬ìš©
            else:
                optimized_chunks.append({
                    'start_ms': start_ms,  # ì‹¤ì œ ì‹œì‘ ìœ„ì¹˜
                    'end_ms': end_ms,      # ì‹¤ì œ ë ìœ„ì¹˜
                    'is_merged': False,
                    'merged_indices': None,
                    'original_ranges': [(start_ms, end_ms)]
                })
                i += 1
        
        # ChunkInfo ê°ì²´ ìƒì„± ë° ì˜¤ë””ì˜¤ ì €ì¥
        final_chunks = []
        for idx, chunk_data in enumerate(optimized_chunks):
            # ì‹¤ì œ ìœ„ì¹˜ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ (ì•ë’¤ ì—¬ìœ  í¬í•¨)
            extract_start = max(0, chunk_data['start_ms'] - 200)  # 0.2ì´ˆ ì•
            extract_end = min(duration_ms, chunk_data['end_ms'] + 200)  # 0.2ì´ˆ ë’¤
            
            chunk_audio = audio[extract_start:extract_end]
            
            # ì²­í¬ ì €ì¥
            chunk_path = os.path.join(temp_dir, f"sentence_{idx:04d}.wav")
            chunk_audio.export(chunk_path, format="wav")
            
            chunk_info = ChunkInfo(
                index=idx,
                path=chunk_path,
                start_ms=chunk_data['start_ms'],  # ì‹¤ì œ ì‹œì‘ ì‹œê°„
                end_ms=chunk_data['end_ms'],      # ì‹¤ì œ ë ì‹œê°„
                duration_ms=chunk_data['end_ms'] - chunk_data['start_ms'],
                has_speech=True,
                overlap_with_next=0,
                is_merged=chunk_data.get('is_merged', False),
                merged_indices=chunk_data.get('merged_indices')
            )
            final_chunks.append(chunk_info)
            
            print(f"  ì²­í¬ {idx + 1}: {chunk_data['start_ms']/1000:.1f}ì´ˆ ~ {chunk_data['end_ms']/1000:.1f}ì´ˆ (ì‹¤ì œ ìœ„ì¹˜)")
        
        print(f"ğŸ“¦ ë¬¸ì¥ ì²­í¬: {len(nonsilent_ranges)}ê°œ ë°œí™” â†’ {len(final_chunks)}ê°œ ì²­í¬ë¡œ ìµœì í™”")
        return final_chunks
    
    def _create_smart_chunks(self, audio_path: str) -> List[ChunkInfo]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ë¶„í•  (ê¸°ì¡´ ë°©ì‹)"""
        if not PYDUB_AVAILABLE:
            return []
        
        from pydub.silence import detect_nonsilent
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_file(audio_path)
        duration_ms = len(audio)
        
        # ë¬´ìŒì´ ì•„ë‹Œ êµ¬ê°„ ê°ì§€
        nonsilent_ranges = detect_nonsilent(
            audio,
            min_silence_len=300,  # 0.3ì´ˆ ì´ìƒ ë¬´ìŒ
            silence_thresh=-40,    # dB
            seek_step=10
        )
        
        chunks = []
        temp_dir = tempfile.mkdtemp()
        chunk_index = 0
        
        # ìµœëŒ€ 15ì´ˆ, ìµœì†Œ 5ì´ˆ ì²­í¬
        max_chunk_ms = 15000
        min_chunk_ms = 5000
        target_overlap_ms = 3000  # 3ì´ˆ ì˜¤ë²„ë©
        
        current_start = 0
        
        print(f"ğŸ“Š ìŠ¤ë§ˆíŠ¸ ë¶„í• : ì´ {duration_ms/1000:.1f}ì´ˆ")
        
        while current_start < duration_ms:
            # ì´ìƒì ì¸ ë ì§€ì 
            ideal_end = min(current_start + max_chunk_ms, duration_ms)
            
            # ì‹¤ì œ ë ì§€ì  ì°¾ê¸° (ë¬´ìŒ êµ¬ê°„ ì°¾ê¸°)
            actual_end = ideal_end
            
            # ideal_end ê·¼ì²˜ì˜ ë¬´ìŒ êµ¬ê°„ ì°¾ê¸°
            for i in range(len(nonsilent_ranges) - 1):
                silence_start = nonsilent_ranges[i][1]
                silence_end = nonsilent_ranges[i + 1][0]
                
                # ë¬´ìŒ êµ¬ê°„ì´ ideal_end ê·¼ì²˜ì— ìˆìœ¼ë©´
                if abs(silence_start - ideal_end) < 2000:  # 2ì´ˆ ì´ë‚´
                    actual_end = silence_start
                    break
            
            # ì²­í¬ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ì¡°ì •
            if actual_end - current_start < min_chunk_ms and actual_end < duration_ms:
                actual_end = min(current_start + max_chunk_ms, duration_ms)
            
            # ì²­í¬ ì¶”ì¶œ (ì˜¤ë²„ë© í¬í•¨)
            chunk_end = min(actual_end + target_overlap_ms, duration_ms)
            chunk = audio[current_start:chunk_end]
            
            # ì €ì¥
            chunk_path = os.path.join(temp_dir, f"chunk_{chunk_index:04d}.wav")
            chunk.export(chunk_path, format="wav")
            chunks.append(ChunkInfo(
                index=chunk_index,
                path=chunk_path,
                start_ms=current_start,
                end_ms=chunk_end,
                duration_ms=chunk_end - current_start,
                has_speech=True,
                overlap_with_next=target_overlap_ms if chunk_end < duration_ms else 0
            ))
            
            print(f"  ì²­í¬ {chunk_index + 1}: {current_start/1000:.1f}ì´ˆ ~ {chunk_end/1000:.1f}ì´ˆ ({(chunk_end-current_start)/1000:.1f}ì´ˆ)")
            
            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ì  (ì˜¤ë²„ë© ì ìš©)
            current_start = actual_end - target_overlap_ms
            if current_start >= duration_ms - min_chunk_ms:
                break
            
            chunk_index += 1
        
        print(f"ğŸ“Š ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
        return chunks
    
    def _api_call_with_retry(self, chunk_path: str, language: str, 
                           max_retries: int = 2) -> ProcessResult:
        """API í˜¸ì¶œ with ì¬ì‹œë„ ë¡œì§"""
        last_error = None
        
        for retry in range(max_retries + 1):
            try:
                # íŒŒì¼ ì½ê¸°
                with open(chunk_path, "rb") as f:
                    audio_contents = base64.b64encode(f.read()).decode("utf8")
                
                # API ìš”ì²­
                request_json = {
                    "argument": {
                        "language_code": language,
                        "audio": audio_contents
                    }
                }
                
                start_time = time.time()
                response = self.http.request(
                    "POST",
                    self.API_URL,
                    headers={
                        "Content-Type": "application/json; charset=UTF-8",
                        "Authorization": self.api_key
                    },
                    body=json.dumps(request_json),
                    timeout=30.0
                )
                duration = time.time() - start_time
                
                if response.status == 200:
                    result = json.loads(response.data.decode("utf-8"))
                    if result.get("result", -1) == 0:
                        text = result.get("return_object", {}).get("recognized", "")
                        return ProcessResult(
                            success=True,
                            text=text,
                            chunk_index=0,
                            duration=duration,
                            retry_count=retry
                        )
                    else:
                        last_error = f"API Error: {result.get('reason', 'Unknown')}"
                else:
                    last_error = f"HTTP Error: {response.status}"
                
                # ì¬ì‹œë„ ì „ ëŒ€ê¸° (exponential backoff)
                if retry < max_retries:
                    wait_time = (2 ** retry) * 1.0  # 1ì´ˆ, 2ì´ˆ, 4ì´ˆ...
                    time.sleep(wait_time)
                    self.processing_stats['retry_count'] += 1
                    
            except Exception as e:
                last_error = str(e)
                if retry < max_retries:
                    time.sleep(1.0)
        
        return ProcessResult(
            success=False,
            text="",
            chunk_index=0,
            duration=0,
            retry_count=max_retries,
            error=last_error
        )
    
    def _process_single(self, chunk: ChunkInfo, language: str, 
                       progress_callback: Optional[Callable]) -> List[ProcessResult]:
        """ë‹¨ì¼ ì²­í¬ ì²˜ë¦¬"""
        if progress_callback:
            progress_callback(50, 100, "ìŒì„± ì¸ì‹ ì¤‘...", None)
        
        result = self._api_call_with_retry(chunk.path, language)
        result.chunk_index = chunk.index
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ ì¶”ê°€
        result.start_time = chunk.start_ms / 1000.0
        result.end_time = chunk.end_ms / 1000.0
        
        if result.success:
            self.processing_stats['success_chunks'] = 1
        else:
            self.processing_stats['failed_chunks'] = 1
        
        if progress_callback:
            progress_callback(100, 100, "ì™„ë£Œ!", None)
        
        return [result]
    
    def _process_sequential(self, chunks: List[ChunkInfo], language: str,
                          progress_callback: Optional[Callable]) -> List[ProcessResult]:
        """ìˆœì°¨ ì²˜ë¦¬"""
        results = []
        total = len(chunks)
        
        for i, chunk in enumerate(chunks):
            # ì§„í–‰ë¥  ê³„ì‚°
            percent = int((i / total) * 100)
            eta = self._calculate_eta(i, total, results)
            
            if progress_callback:
                progress_callback(percent, 100, f"ì²­í¬ {i+1}/{total} ì²˜ë¦¬ ì¤‘...", eta)
            
            # ìŒì„±ì´ ì—†ëŠ” ì²­í¬ëŠ” ê±´ë„ˆë›°ê¸°
            if not chunk.has_speech:
                results.append(ProcessResult(
                    success=True,
                    text="",
                    chunk_index=chunk.index,
                    duration=0,
                    start_time=chunk.start_ms / 1000.0,
                    end_time=chunk.end_ms / 1000.0
                ))
                continue
            
            # API í˜¸ì¶œ
            result = self._api_call_with_retry(chunk.path, language)
            result.chunk_index = chunk.index
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ ì¶”ê°€
            result.start_time = chunk.start_ms / 1000.0
            result.end_time = chunk.end_ms / 1000.0
            
            results.append(result)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if result.success:
                self.processing_stats['success_chunks'] += 1
            else:
                self.processing_stats['failed_chunks'] += 1
            
            # ë‹¤ìŒ ìš”ì²­ ì „ ëŒ€ê¸°
            if i < total - 1:
                time.sleep(1.0)
        
        return results
    
    def _process_parallel(self, chunks: List[ChunkInfo], language: str,
                        max_workers: int, progress_callback: Optional[Callable]) -> List[ProcessResult]:
        """ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 2ì›Œì»¤)"""
        results = []
        total = len(chunks)
        completed = 0
        
        # ì›Œì»¤ ìˆ˜ ì œí•œ
        max_workers = min(max_workers, 2)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ì‘ì—… ì œì¶œ
            future_to_chunk = {}
            
            for i, chunk in enumerate(chunks):
                # ìŒì„± ì—†ëŠ” ì²­í¬ëŠ” ì¦‰ì‹œ ì²˜ë¦¬
                if not chunk.has_speech:
                    results.append(ProcessResult(
                        success=True,
                        text="",
                        chunk_index=chunk.index,
                        duration=0,
                        start_time=chunk.start_ms / 1000.0,
                        end_time=chunk.end_ms / 1000.0
                    ))
                    completed += 1
                    continue
                
                # 2ê°œì”© ë°°ì¹˜ë¡œ ì œì¶œ (API ë¶€í•˜ ê´€ë¦¬)
                if i > 0 and i % 2 == 0:
                    time.sleep(0.5)
                
                future = executor.submit(
                    self._api_call_with_retry,
                    chunk.path,
                    language
                )
                future_to_chunk[future] = chunk
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future in as_completed(future_to_chunk):
                chunk = future_to_chunk[future]
                
                try:
                    result = future.result(timeout=30)
                    result.chunk_index = chunk.index
                    
                    # íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ ì¶”ê°€
                    result.start_time = chunk.start_ms / 1000.0
                    result.end_time = chunk.end_ms / 1000.0
                    
                    results.append(result)
                    
                    if result.success:
                        self.processing_stats['success_chunks'] += 1
                    else:
                        self.processing_stats['failed_chunks'] += 1
                        # ì‹¤íŒ¨í•œ ì²­í¬ ì¬ì‹œë„ (í•œ ë²ˆ ë”)
                        if result.retry_count < 3:
                            time.sleep(2.0)
                            retry_result = self._api_call_with_retry(chunk.path, language, max_retries=1)
                            if retry_result.success:
                                results[-1] = retry_result  # êµì²´
                                self.processing_stats['success_chunks'] += 1
                                self.processing_stats['failed_chunks'] -= 1
                    
                except Exception as e:
                    results.append(ProcessResult(
                        success=False,
                        text="",
                        chunk_index=chunk.index,
                        duration=0,
                        error=str(e),
                        start_time=chunk.start_ms / 1000.0,
                        end_time=chunk.end_ms / 1000.0
                    ))
                    self.processing_stats['failed_chunks'] += 1
                
                completed += 1
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                if progress_callback:
                    percent = int((completed / total) * 100)
                    eta = self._calculate_eta(completed, total, results)
                    progress_callback(percent, 100, f"ë³‘ë ¬ ì²˜ë¦¬ ì¤‘... {completed}/{total}", eta)
        
        # ì¸ë±ìŠ¤ ìˆœìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x.chunk_index)
        return results
    
    def _organize_with_timestamps(self, results: List[ProcessResult], 
                                  chunks: List[ChunkInfo]) -> List[Dict]:
        """íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í•¨ê»˜ ê²°ê³¼ ì •ë¦¬ (ê°œì„ ëœ ë²„ì „)"""
        sentences = []
        
        for result in results:
            if not result.success or not result.text:
                continue
            
            # í•´ë‹¹ ì²­í¬ ì°¾ê¸°
            chunk = next((c for c in chunks if c.index == result.chunk_index), None)
            if not chunk:
                continue
            
            # ì´ë¯¸ ì •í™•í•œ ì‹œê°„ì´ ìˆìŒ
            actual_start = result.start_time  # ì´ë¯¸ ì´ˆ ë‹¨ìœ„
            actual_end = result.end_time
            
            if chunk.is_merged and chunk.merged_indices:
                # ë³‘í•©ëœ ì²­í¬: ë¬¸ì¥ ë¶„ë¦¬ í›„ ì‹œê°„ ë°°ë¶„
                text_sentences = self._split_text_to_sentences(result.text)
                
                if len(text_sentences) == 1:
                    # ë‹¨ì¼ ë¬¸ì¥
                    sentences.append({
                        'text': result.text.strip(),
                        'start_time': actual_start,
                        'end_time': actual_end
                    })
                else:
                    # ì—¬ëŸ¬ ë¬¸ì¥: ê¸€ì ìˆ˜ ë¹„ë¡€ë¡œ ì‹œê°„ ë°°ë¶„ (ê· ë“± ë¶„ë°°ë³´ë‹¤ ì •í™•)
                    total_chars = sum(len(s) for s in text_sentences)
                    total_duration = actual_end - actual_start
                    current_time = actual_start
                    
                    for sent_text in text_sentences:
                        # ê¸€ì ìˆ˜ ë¹„ë¡€ë¡œ ì‹œê°„ í• ë‹¹
                        if total_chars > 0:
                            sent_duration = (len(sent_text) / total_chars) * total_duration
                        else:
                            sent_duration = total_duration / len(text_sentences)
                        
                        sentences.append({
                            'text': sent_text.strip(),
                            'start_time': current_time,
                            'end_time': min(current_time + sent_duration, actual_end)
                        })
                        current_time += sent_duration
            else:
                # ë‹¨ì¼ ì²­í¬
                sentences.append({
                    'text': result.text.strip(),
                    'start_time': actual_start,
                    'end_time': actual_end
                })
        
        # ì‹œê°„ìˆœ ì •ë ¬ (ì´ë¯¸ ì •ë ¬ë˜ì–´ ìˆê² ì§€ë§Œ í™•ì‹¤íˆ)
        sentences.sort(key=lambda x: x['start_time'])
        
        # ì¤‘ë³µ ì œê±° ë° ì‹œê°„ ì¡°ì •
        if len(sentences) > 1:
            cleaned_sentences = []
            prev_sentence = None
            
            for sentence in sentences:
                # ì´ì „ ë¬¸ì¥ê³¼ ê²¹ì¹˜ëŠ” ê²½ìš° ì¡°ì •
                if prev_sentence and sentence['start_time'] < prev_sentence['end_time']:
                    # ì‹œì‘ ì‹œê°„ ì¡°ì •
                    sentence['start_time'] = prev_sentence['end_time']
                
                # ì‹œì‘ì´ ëë³´ë‹¤ ëŠ¦ì€ ê²½ìš° ìŠ¤í‚µ
                if sentence['start_time'] >= sentence['end_time']:
                    continue
                
                cleaned_sentences.append(sentence)
                prev_sentence = sentence
            
            sentences = cleaned_sentences
        
        return sentences
    
    def _split_text_to_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬"""
        import re
        
        # ë¬¸ì¥ ì¢…ê²° íŒ¨í„´ìœ¼ë¡œ ë¶„ë¦¬
        sentences = re.split(r'(?<=[.!?])\s+', text)
        
        # ë¹ˆ ë¬¸ì¥ ì œê±°
        sentences = [s.strip() for s in sentences if s.strip()]
        
        return sentences if sentences else [text]
    
    def _extract_plain_text(self, sentences: List[Dict]) -> str:
        """ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return " ".join(s['text'] for s in sentences if s.get('text'))
    
    def _format_with_timestamps(self, sentences: List[Dict]) -> str:
        """íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í¬ë§·íŒ…"""
        formatted_lines = []
        
        for sentence in sentences:
            # ì‹œê°„ í¬ë§· (MM:SS)
            minutes = int(sentence['start_time'] // 60)
            seconds = int(sentence['start_time'] % 60)
            timestamp = f"[{minutes:02d}:{seconds:02d}]"
            
            # ë¬¸ì¥ ì¶”ê°€
            formatted_lines.append(f"{timestamp} {sentence['text']}")
            formatted_lines.append("")  # ë¹ˆ ì¤„ ì¶”ê°€ (ê°€ë…ì„±)
        
        return "\n".join(formatted_lines)
    
    def _merge_results(self, results: List[ProcessResult]) -> str:
        """ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±° (ê¸°ì¡´ ë°©ì‹)"""
        if not results:
            return ""
        
        texts = []
        previous_text = ""
        
        for i, result in enumerate(results):
            if not result.success or not result.text:
                # ì‹¤íŒ¨í•œ ì²­í¬ ì²˜ë¦¬ - ì´ì „/ì´í›„ ì²­í¬ì˜ ì˜¤ë²„ë© ë¶€ë¶„ í™œìš©
                if i > 0 and i < len(results) - 1:
                    # ì´ì „ê³¼ ë‹¤ìŒ ì²­í¬ ì‚¬ì´ë¥¼ ë³´ê°„
                    texts.append("[...]")  # ëˆ„ë½ í‘œì‹œ
                continue
            
            current_text = result.text.strip()
            
            # ì˜¤ë²„ë© ì¤‘ë³µ ì œê±°
            if i > 0 and previous_text:
                # ë§ˆì§€ë§‰ nê¸€ìì™€ ì²« nê¸€ì ë¹„êµ
                overlap_found = False
                for check_len in range(min(50, len(previous_text)//2), 5, -1):
                    last_part = previous_text[-check_len:]
                    if current_text.startswith(last_part):
                        current_text = current_text[check_len:].strip()
                        overlap_found = True
                        break
                
                # ë‹¨ì–´ ë‹¨ìœ„ ì¤‘ë³µ ì²´í¬ (ë” ì •êµí•˜ê²Œ)
                if not overlap_found:
                    prev_words = previous_text.split()[-5:]  # ë§ˆì§€ë§‰ 5ë‹¨ì–´
                    curr_words = current_text.split()[:5]    # ì²˜ìŒ 5ë‹¨ì–´
                    
                    for j in range(min(len(prev_words), len(curr_words))):
                        if prev_words[-j-1:] == curr_words[:j+1]:
                            current_text = ' '.join(curr_words[j+1:] + current_text.split()[5:])
                            break
            
            if current_text:
                # ë¬¸ì¥ ë¶€í˜¸ ì •ë¦¬
                if texts and not texts[-1].endswith(('.', '!', '?')):
                    if not current_text[0].isupper():
                        texts[-1] += '.'
                
                texts.append(current_text)
                previous_text = result.text.strip()
        
        # ìµœì¢… ê²°í•©
        final_text = ' '.join(texts)
        
        # í›„ì²˜ë¦¬
        final_text = ' '.join(final_text.split())  # ì¤‘ë³µ ê³µë°± ì œê±°
        final_text = final_text.replace(' .', '.')
        final_text = final_text.replace(' ,', ',')
        final_text = final_text.replace(' ?', '?')
        final_text = final_text.replace(' !', '!')
        
        return final_text
    
    def _calculate_eta(self, completed: int, total: int, 
                      results: List[ProcessResult]) -> Optional[int]:
        """ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚°"""
        if completed == 0 or not results:
            return None
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        avg_duration = sum(r.duration for r in results if r.duration > 0) / max(1, len(results))
        remaining = total - completed
        eta_seconds = int(remaining * avg_duration)
        
        return eta_seconds


# ê°„í¸ ì‚¬ìš© í•¨ìˆ˜
def transcribe_audio(audio_path: str, api_key: str, 
                     max_workers: int = 2,
                     progress_callback: Optional[Callable] = None,
                     enable_timestamps: bool = True) -> Dict:
    """
    ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (íƒ€ì„ìŠ¤íƒ¬í”„ ì˜µì…˜ ì¶”ê°€)
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        api_key: ETRI API í‚¤
        max_workers: ë³‘ë ¬ ì›Œì»¤ ìˆ˜ (1-2)
        progress_callback: ì§„í–‰ ì½œë°±
        enable_timestamps: íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ì—¬ë¶€
    
    Returns:
        {
            'success': bool, 
            'text': str, 
            'formatted_text': str (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨),
            'sentences': list (ë¬¸ì¥ë³„ ì •ë³´),
            'stats': dict
        }
    """
    processor = ImprovedSTTProcessor(api_key)
    return processor.process(
        audio_path, 
        max_workers=max_workers, 
        progress_callback=progress_callback,
        enable_timestamps=enable_timestamps
    )