# conservative_corrector.py
"""
ë³´ìˆ˜ì  STT í…ìŠ¤íŠ¸ ë³´ì • ì‹œìŠ¤í…œ
í™•ì‹¤í•œ ê²ƒë§Œ ìˆ˜ì •í•˜ê³ , ì• ë§¤í•œ ë¶€ë¶„ì€ ì‚¬ìš©ì ê²€í†  ìš”ì²­
"""

import os
import json
import re
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from openai import OpenAI


@dataclass
class SuspiciousPart:
    """ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë¶€ë¶„"""
    text: str
    start: int
    end: int
    confidence: float
    reason: str
    suggestions: List[str] = field(default_factory=list)
    linguistic_type: str = ""  # ìŒìš´ì /ì˜ë¯¸ì /ë¬¸ë²•ì 


@dataclass
class CorrectionResult:
    """ë³´ì • ê²°ê³¼"""
    original_text: str
    corrected_text: str
    suspicious_parts: List[SuspiciousPart]
    auto_corrections: List[Dict]
    needs_review: bool
    context_analysis: Dict = field(default_factory=dict)  # ë¬¸ë§¥ ë¶„ì„ ê²°ê³¼


class ConservativeCorrector:
    """ë³´ìˆ˜ì  í…ìŠ¤íŠ¸ ë³´ì •ê¸°"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o-mini"):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        self.client = OpenAI(api_key=self.api_key)
        self.model = model
    
    def create_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ì—­í•  ì •ì˜"""
        return """You are a Korean STT post-processor with expertise in:
1. Korean phonology and common misrecognition patterns
2. Natural language understanding for context analysis
3. Conservative correction - only fix what's certain

Your task is to:
- Identify potential STT errors based on phonetic similarity
- Consider semantic coherence within the context
- Mark suspicious parts rather than auto-correcting uncertain cases

Key principles:
- STT often confuses words with similar pronunciation
- Single syllables can be incorrectly separated or merged
- Context is crucial for identifying errors
- When in doubt, mark as suspicious rather than correct"""
    
    def create_analysis_prompt(self, text: str) -> str:
        """1ë‹¨ê³„: ë¬¸ë§¥ ë¶„ì„ í”„ë¡¬í”„íŠ¸"""
        return f"""ë‹¤ìŒ STT ì¶œë ¥ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”:

í…ìŠ¤íŠ¸:
{text}

ë¶„ì„ í•­ëª©:
1. ì „ì²´ ëŒ€í™”ì˜ ì£¼ì œ/ìƒí™© íŒŒì•…
2. ê° ë¬¸ì¥ì˜ ì˜ë¯¸ì  ì™„ì„±ë„
3. ë¬¸ì¥ ê°„ ì˜ë¯¸ ì—°ê²°ì„±
4. ì–´ìƒ‰í•˜ê±°ë‚˜ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„

JSON í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”:
{{
    "topic": "ëŒ€í™” ì£¼ì œ",
    "context_type": "ì¼ìƒëŒ€í™”|ì˜ë£Œìƒë‹´|ì‹¬ë¦¬ìƒë‹´|ì—…ë¬´ëŒ€í™”|ê¸°íƒ€",
    "sentence_analysis": [
        {{
            "sentence": "ë¬¸ì¥",
            "semantic_completeness": 0.0-1.0,
            "issues": ["ë°œê²¬ëœ ë¬¸ì œì "]
        }}
    ],
    "overall_coherence": 0.0-1.0
}}"""
    
    def create_conservative_prompt(self, text: str, context: Optional[Dict] = None) -> str:
        """2ë‹¨ê³„: ë³´ìˆ˜ì  ë³´ì • í”„ë¡¬í”„íŠ¸"""
        
        context_info = ""
        if context:
            context_info = f"""
ë¬¸ë§¥ ì •ë³´:
- ì£¼ì œ: {context.get('topic', 'ë¶ˆëª…')}
- ìœ í˜•: {context.get('context_type', 'ì¼ë°˜')}
- ì „ì²´ ì¼ê´€ì„±: {context.get('overall_coherence', 0):.1f}
"""
        
        prompt = f"""STT í…ìŠ¤íŠ¸ë¥¼ ë³´ìˆ˜ì ìœ¼ë¡œ ë³´ì •í•˜ì„¸ìš”.
{context_info}

ë³´ì • ì›ì¹™:
1. í™•ì‹¤í•œ ê²ƒë§Œ ìˆ˜ì •:
   - ë¬¸ì¥ë¶€í˜¸ ì¶”ê°€ (? . , !)
   - ëª…ë°±í•œ ë„ì–´ì“°ê¸° ì˜¤ë¥˜
   - ì¤‘ë³µëœ ì¡°ì‚¬ (ì„ë¥¼ â†’ ë¥¼)

2. ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë¶€ë¶„ íƒì§€ (í•µì‹¬):
   ìŒìš´ì  ì˜¤ë¥˜ ê°€ëŠ¥ì„±:
   - ë°œìŒ ìœ ì‚¬ ë‹¨ì–´ (ã„·/ã…Œ, ã…‚/ã…, ã„±/ã…‹ í˜¼ë™)
   - ì—°ìŒìœ¼ë¡œ ì¸í•œ ì˜¤ì¸ì‹
   - ìŒì ˆ ë¶„ë¦¬/ê²°í•© ì˜¤ë¥˜
   
   ì˜ë¯¸ì  ì˜¤ë¥˜ ê°€ëŠ¥ì„±:
   - ë¬¸ë§¥ê³¼ ë§ì§€ ì•ŠëŠ” ë‹¨ì–´
   - ì£¼ì–´-ì„œìˆ ì–´ ì˜ë¯¸ ë¶ˆì¼ì¹˜
   - ì „í›„ ë¬¸ì¥ê³¼ ì—°ê²° ì•ˆ ë˜ëŠ” ë‚´ìš©
   
   ë¬¸ë²•ì  ì˜¤ë¥˜ ê°€ëŠ¥ì„±:
   - ì¡°ì‚¬ ë¶ˆì¼ì¹˜ (ë°›ì¹¨ ìœ ë¬´)
   - ì–´ë¯¸ í™œìš© ì˜¤ë¥˜
   - ì–´ìˆœ ì´ìƒ

3. ìˆ˜ì •í•˜ì§€ ë§ ê²ƒ:
   - êµ¬ì–´ì²´ í‘œí˜„
   - ë°©ì–¸ì´ë‚˜ ì¤„ì„ë§
   - ê°ì • í‘œí˜„

ì›ë³¸ í…ìŠ¤íŠ¸:
{text}

ë¶„ì„ ë°©ë²•:
1. ê° ë¬¸ì¥ì„ ìŒì„±ìœ¼ë¡œ ë°œí™”í–ˆì„ ë•Œë¥¼ ìƒìƒ
2. ìœ ì‚¬í•œ ë°œìŒìœ¼ë¡œ ì˜¤ì¸ì‹ë  ìˆ˜ ìˆëŠ” ë¶€ë¶„ ì°¾ê¸°
3. ì „í›„ ë¬¸ë§¥ê³¼ ì˜ë¯¸ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ëŠ”ì§€ í™•ì¸

JSON ì‘ë‹µ:
{{
    "corrected_text": "ë³´ìˆ˜ì ìœ¼ë¡œ ë³´ì •ëœ í…ìŠ¤íŠ¸",
    "auto_corrections": [
        {{
            "type": "punctuation|spacing|duplicate",
            "original": "ì›ë³¸ í…ìŠ¤íŠ¸",
            "corrected": "ìˆ˜ì •ëœ í…ìŠ¤íŠ¸",
            "confidence": 0.9,
            "position": ì‹œì‘ìœ„ì¹˜
        }}
    ],
    "suspicious_parts": [
        {{
            "text": "ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë¶€ë¶„",
            "start_char": ì‹œì‘ìœ„ì¹˜,
            "end_char": ëìœ„ì¹˜,
            "confidence": 0.3,
            "reason": "êµ¬ì²´ì  ì´ìœ ",
            "linguistic_type": "phonetic|semantic|grammatical",
            "suggestions": ["ëŒ€ì•ˆ1", "ëŒ€ì•ˆ2"],
            "context_clue": "íŒë‹¨ ê·¼ê±°ê°€ ëœ ì£¼ë³€ ë¬¸ë§¥"
        }}
    ]
}}

ì¤‘ìš”: 
- confidenceê°€ 0.5 ì´í•˜ì¸ ëª¨ë“  ì˜ì‹¬ êµ¬ê°„ì„ suspicious_partsì— í¬í•¨
- ìŒìš´ì ìœ¼ë¡œ ìœ ì‚¬í•œ ëŒ€ì•ˆì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ suggestionsì— í¬í•¨
- reasonì€ êµ¬ì²´ì ì´ê³  ì–¸ì–´í•™ì  ê·¼ê±°ë¥¼ ì œì‹œ"""
        
        return prompt
    
    def apply_basic_rules(self, text: str) -> Tuple[str, List[Dict]]:
        """ê¸°ë³¸ ê·œì¹™ ì ìš© (GPT í˜¸ì¶œ ì „)"""
        
        corrections = []
        result = text
        
        # 1. ì¤‘ë³µ ì¡°ì‚¬ ì œê±°
        duplicates = [
            (r'ì„ë¥¼', 'ë¥¼'),
            (r'ì´ê°€', 'ê°€'),
            (r'ì€ëŠ”', 'ëŠ”'),
            (r'ê³¼ì™€', 'ì™€'),
        ]
        
        for pattern, replacement in duplicates:
            if re.search(pattern, result):
                # ìœ„ì¹˜ ì°¾ê¸°
                for match in re.finditer(pattern, result):
                    corrections.append({
                        "type": "duplicate",
                        "original": pattern,
                        "corrected": replacement,
                        "confidence": 1.0,
                        "position": match.start()
                    })
                result = re.sub(pattern, replacement, result)
        
        # 2. ëª…ë°±í•œ ë„ì–´ì“°ê¸° (ë§¤ìš° ë³´ìˆ˜ì )
        # ì˜ˆ: "ê·¸ëŸ°ë°ìš”" â†’ "ê·¸ëŸ°ë° ìš”" (X, êµ¬ì–´ì²´ ë³´ì¡´)
        # ì˜ˆ: "í–ˆìŠµë‹ˆë‹¤.ê·¸ë˜ì„œ" â†’ "í–ˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ" (O)
        result = re.sub(r'([.!?])([ê°€-í£])', r'\1 \2', result)
        
        # 3. ì—°ì† ê³µë°± ì œê±°
        result = re.sub(r'\s+', ' ', result).strip()
        
        return result, corrections
    
    def analyze_context(self, text: str) -> Dict:
        """ë¬¸ë§¥ ë¶„ì„ (ì„ íƒì )"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a Korean language expert analyzing STT output."
                    },
                    {"role": "user", "content": self.create_analysis_prompt(text)}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"âš ï¸ ë¬¸ë§¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def correct(self, text: str, use_context_analysis: bool = True) -> CorrectionResult:
        """ë³´ìˆ˜ì  ë³´ì • ì‹¤í–‰"""
        
        # ê¸°ë³¸ ê·œì¹™ ì ìš©
        pre_corrected, rule_corrections = self.apply_basic_rules(text)
        
        # ë¬¸ë§¥ ë¶„ì„ (ì„ íƒì )
        context = {}
        if use_context_analysis:
            print("ğŸ” ë¬¸ë§¥ ë¶„ì„ ì¤‘...")
            context = self.analyze_context(pre_corrected)
        
        # GPT ë³´ì • í˜¸ì¶œ
        prompt = self.create_conservative_prompt(pre_corrected, context)
        
        try:
            print("âœï¸ ë³´ì • ë¶„ì„ ì¤‘...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": self.create_system_prompt()
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,  # 0.1ì—ì„œ 0.2ë¡œ ì•½ê°„ ìƒí–¥
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë¶€ë¶„ íŒŒì‹±
            suspicious_parts = []
            for susp in result.get("suspicious_parts", []):
                suspicious_parts.append(SuspiciousPart(
                    text=susp["text"],
                    start=susp.get("start_char", 0),
                    end=susp.get("end_char", 0),
                    confidence=susp.get("confidence", 0.5),
                    reason=susp.get("reason", ""),
                    suggestions=susp.get("suggestions", []),
                    linguistic_type=susp.get("linguistic_type", "")
                ))
            
            # ìë™ ìˆ˜ì • ì‚¬í•­ ë³‘í•©
            all_corrections = rule_corrections + result.get("auto_corrections", [])
            
            return CorrectionResult(
                original_text=text,
                corrected_text=result.get("corrected_text", pre_corrected),
                suspicious_parts=suspicious_parts,
                auto_corrections=all_corrections,
                needs_review=len(suspicious_parts) > 0,
                context_analysis=context
            )
            
        except Exception as e:
            print(f"âŒ GPT ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê·œì¹™ë§Œ ì ìš©
            return CorrectionResult(
                original_text=text,
                corrected_text=pre_corrected,
                suspicious_parts=[],
                auto_corrections=rule_corrections,
                needs_review=False,
                context_analysis=context
            )


class InteractiveReviewer:
    """ì‚¬ìš©ì ê²€í†  ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.review_history = []
    
    def display_for_review(self, result: CorrectionResult) -> Dict:
        """ê²€í† ìš© í‘œì‹œ ë°ì´í„° ìƒì„±"""
        
        display_data = {
            "text": result.corrected_text,
            "highlights": [],
            "review_needed": result.needs_review,
            "context": result.context_analysis
        }
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë¶€ë¶„ í•˜ì´ë¼ì´íŠ¸ ì •ë³´
        for susp in result.suspicious_parts:
            highlight = {
                "start": susp.start,
                "end": susp.end,
                "text": susp.text,
                "reason": susp.reason,
                "linguistic_type": susp.linguistic_type,
                "suggestions": susp.suggestions,
                "confidence": susp.confidence
            }
            
            # ì–¸ì–´í•™ì  íƒ€ì…ë³„ ìƒ‰ìƒ
            if susp.linguistic_type == "phonetic":
                highlight["color"] = "#FF6B6B"  # ë¹¨ê°• - ìŒìš´ì 
            elif susp.linguistic_type == "semantic":
                highlight["color"] = "#4ECDC4"  # ì²­ë¡ - ì˜ë¯¸ì 
            elif susp.linguistic_type == "grammatical":
                highlight["color"] = "#45B7D1"  # íŒŒë‘ - ë¬¸ë²•ì 
            else:
                highlight["color"] = "#FFA07A"  # ì£¼í™© - ê¸°íƒ€
            
            display_data["highlights"].append(highlight)
        
        # ìë™ ìˆ˜ì • ì‚¬í•­ ìš”ì•½
        display_data["auto_corrections_summary"] = self._summarize_corrections(
            result.auto_corrections
        )
        
        return display_data
    
    def _summarize_corrections(self, corrections: List[Dict]) -> str:
        """ìë™ ìˆ˜ì • ì‚¬í•­ ìš”ì•½"""
        
        if not corrections:
            return "ìë™ ìˆ˜ì • ì—†ìŒ"
        
        summary = []
        types = {}
        for corr in corrections:
            corr_type = corr.get("type", "ê¸°íƒ€")
            types[corr_type] = types.get(corr_type, 0) + 1
        
        for corr_type, count in types.items():
            if corr_type == "punctuation":
                summary.append(f"ë¬¸ì¥ë¶€í˜¸ {count}ê°œ")
            elif corr_type == "duplicate":
                summary.append(f"ì¤‘ë³µ ì¡°ì‚¬ {count}ê°œ")
            elif corr_type == "spacing":
                summary.append(f"ë„ì–´ì“°ê¸° {count}ê°œ")
            else:
                summary.append(f"{corr_type} {count}ê°œ")
        
        return ", ".join(summary)
    
    def apply_user_corrections(self, result: CorrectionResult, 
                              user_choices: Dict[str, str]) -> str:
        """ì‚¬ìš©ì ì„ íƒ ì ìš©"""
        
        final_text = result.corrected_text
        
        # ì‚¬ìš©ì ì„ íƒ ì ìš© (ì—­ìˆœìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì¸ë±ìŠ¤ ê¼¬ì„ ë°©ì§€)
        replacements = []
        for original, replacement in user_choices.items():
            # í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ë¶€ë¶„ ì°¾ê¸°
            idx = final_text.find(original)
            if idx >= 0:
                replacements.append((idx, original, replacement))
        
        # ìœ„ì¹˜ ì—­ìˆœ ì •ë ¬
        replacements.sort(reverse=True)
        
        # ì¹˜í™˜ ì ìš©
        for idx, original, replacement in replacements:
            final_text = final_text[:idx] + replacement + final_text[idx + len(original):]
        
        # ê¸°ë¡ ì €ì¥
        self.review_history.append({
            "original": result.original_text,
            "auto_corrected": result.corrected_text,
            "user_choices": user_choices,
            "final": final_text,
            "context": result.context_analysis
        })
        
        return final_text


# í¸ì˜ í•¨ìˆ˜
def conservative_correct_with_review(text: str, api_key: Optional[str] = None,
                                    use_context: bool = True) -> Dict:
    """
    ë³´ìˆ˜ì  ë³´ì • + ê²€í†  í•„ìš” ì—¬ë¶€ ë°˜í™˜
    
    Args:
        text: STT ì¶œë ¥ í…ìŠ¤íŠ¸
        api_key: OpenAI API í‚¤
        use_context: ë¬¸ë§¥ ë¶„ì„ ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        {
            "corrected": ë³´ì •ëœ í…ìŠ¤íŠ¸,
            "needs_review": ê²€í†  í•„ìš” ì—¬ë¶€,
            "review_items": ê²€í†  í•­ëª©ë“¤,
            "summary": ìš”ì•½,
            "context": ë¬¸ë§¥ ë¶„ì„ ê²°ê³¼
        }
    """
    
    corrector = ConservativeCorrector(api_key)
    reviewer = InteractiveReviewer()
    
    # ë³´ì • ì‹¤í–‰
    result = corrector.correct(text, use_context_analysis=use_context)
    
    # ê²€í† ìš© ë°ì´í„° ìƒì„±
    display_data = reviewer.display_for_review(result)
    
    return {
        "corrected": result.corrected_text,
        "needs_review": result.needs_review,
        "review_items": display_data["highlights"],
        "auto_corrections": display_data["auto_corrections_summary"],
        "original": text,
        "context": display_data.get("context", {})
    }


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    test_text = """ìµœê·¼ì— ê±´ê°•ì€ ì–´ë•Œ ê±´ê°•í•œ ê²ƒ ê°™ì•„ìš”. ìµœê·¼ì— ë” ì¹œ ê³³ ìˆì–´? 
    ì•„ë¹ ê°€ ê½‰ ì¡ì•„ì„œ ì–´ê¹¨ê°€ ì•„íŒŒìš”. ì–¸ì œ ë‹¤ì³¤ì–´ ì´ë²ˆ ì£¼ ì›”ìš”ì¼ì´ì•¼"""
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âš ï¸ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
    else:
        print("="*60)
        print("ğŸ” ë³´ìˆ˜ì  ë³´ì • + ì‚¬ìš©ì ê²€í†  ì‹œìŠ¤í…œ")
        print("="*60)
        
        # ë³´ì • ì‹¤í–‰
        result = conservative_correct_with_review(test_text, api_key)
        
        print(f"\nğŸ“ ì›ë³¸:")
        print(result["original"])
        
        print(f"\nâœï¸ ìë™ ë³´ì •:")
        print(result["corrected"])
        print(f"ìë™ ìˆ˜ì •: {result['auto_corrections']}")
        
        if result.get("context"):
            print(f"\nğŸ“Š ë¬¸ë§¥ ë¶„ì„:")
            print(f"ì£¼ì œ: {result['context'].get('topic', 'ë¶ˆëª…')}")
            print(f"ìœ í˜•: {result['context'].get('context_type', 'ì¼ë°˜')}")
            print(f"ì¼ê´€ì„±: {result['context'].get('overall_coherence', 0):.1f}")
        
        if result["needs_review"]:
            print(f"\nâš ï¸ ê²€í†  í•„ìš”: {len(result['review_items'])}ê°œ í•­ëª©")
            for i, item in enumerate(result["review_items"], 1):
                print(f"\n  {i}. [{item['text']}]")
                print(f"     ìœ í˜•: {item.get('linguistic_type', 'ì¼ë°˜')}")
                print(f"     ì´ìœ : {item['reason']}")
                print(f"     ì œì•ˆ: {item['suggestions']}")
                print(f"     ì‹ ë¢°ë„: {item['confidence']:.0%}")
        else:
            print("\nâœ… ê²€í†  í•„ìš” ì—†ìŒ")