# etri_ner_detector.py
"""
ETRI ê°œì²´ëª… ì¸ì‹ APIë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ PII íƒì§€ ëª¨ë“ˆ
ETRI NERì´ ë©”ì¸, ì •ê·œì‹ì€ ë³´ì¡° ì—­í• 
"""

import json
import urllib3
import re
from typing import List, Dict, Optional, Tuple, Set
from dataclasses import dataclass
from collections import defaultdict

# SSL ê²½ê³  ë¹„í™œì„±í™”
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

@dataclass
class PIIEntity:
    """PII ì—”í‹°í‹° ë°ì´í„° í´ë˜ìŠ¤"""
    text: str
    label: str
    subtype: str
    start: int
    end: int
    score: float
    source: str  # 'etri', 'regex', 'merged'
    metadata: Dict = None


class ETRILanguageAnalyzer:
    """ETRI ì–¸ì–´ ë¶„ì„ API í´ë¼ì´ì–¸íŠ¸ - ë©”ì¸ íƒì§€ ì—”ì§„"""
    
    # API ì—”ë“œí¬ì¸íŠ¸
    API_URL_WRITTEN = "http://epretx.etri.re.kr:8000/api/WiseNLU"
    API_URL_SPOKEN = "http://epretx.etri.re.kr:8000/api/WiseNLU_spoken"
    
    # ETRI ê°œì²´ëª… íƒœê·¸ â†’ PII ë¼ë²¨ ë§¤í•‘ (í™•ì¥)
    TAG_TO_PII = {
        # === ê°œì¸ ì‹ ì› ===
        "PS_NAME": ("ì´ë¦„", "ì¸ëª…"),
        
        # === ì—°ë½ì²˜/ê³„ì • ===
        "QT_PHONE": ("ë²ˆí˜¸", "ì „í™”ë²ˆí˜¸"),
        "TMI_EMAIL": ("ê³„ì •", "ì´ë©”ì¼"),
        "TMI_SITE": ("URL", "ì›¹ì‚¬ì´íŠ¸"),
        
        # === ì£¼ì†Œ/ìœ„ì¹˜ ===
        "QT_ZIPCODE": ("ì£¼ì†Œ", "ìš°í¸ë²ˆí˜¸"),
        "LCP_COUNTRY": ("ì£¼ì†Œ", "êµ­ê°€"),
        "LCP_PROVINCE": ("ì£¼ì†Œ", "ë„/ì£¼"),
        "LCP_COUNTY": ("ì£¼ì†Œ", "êµ°/êµ¬/ë™"),
        "LCP_CITY": ("ì£¼ì†Œ", "ë„ì‹œ"),
        "LC_OTHERS": ("ì£¼ì†Œ", "ê¸°íƒ€ì¥ì†Œ"),
        "AF_BUILDING": ("ì£¼ì†Œ", "ê±´ë¬¼ëª…"),
        
        # === ì†Œì†/ì¡°ì§ ===
        "OGG_ECONOMY": ("ì†Œì†", "ê¸°ì—…"),
        "OGG_EDUCATION": ("ì†Œì†", "êµìœ¡ê¸°ê´€"),
        "OGG_POLITICS": ("ì†Œì†", "ì •ë¶€ê¸°ê´€"),
        "OGG_MEDICINE": ("ì†Œì†", "ì˜ë£Œê¸°ê´€"),
        "OGG_MEDIA": ("ì†Œì†", "ì–¸ë¡ ì‚¬"),
        "OG_OTHERS": ("ì†Œì†", "ê¸°íƒ€ê¸°ê´€"),
        
        # === ê¸ˆìœµ ===
        "QT_PRICE": ("ê¸ˆìœµ", "ê¸ˆì•¡"),
        "CV_CURRENCY": ("ê¸ˆìœµ", "í†µí™”"),
        
        # === ê°œì¸ì •ë³´ ===
        "QT_AGE": ("ì‹ ì›", "ë‚˜ì´"),
        "TMM_DISEASE": ("ì‹ ì›", "ê±´ê°•ì •ë³´"),
        "DT_DAY": ("ì‹ ì›", "ë‚ ì§œ"),
        "TI_HOUR": ("ì‹ ì›", "ì‹œê°„"),
        "CV_OCCUPATION": ("ì‹ ì›", "ì§ì—…"),
        "CV_POSITION": ("ì‹ ì›", "ì§ìœ„"),
    }
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.http = urllib3.PoolManager()
    
    def analyze(self, text: str, use_spoken: bool = False) -> Dict:
        """
        ETRI ì–¸ì–´ ë¶„ì„ API í˜¸ì¶œ
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            use_spoken: êµ¬ì–´ì²´ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            API ì‘ë‹µ ê²°ê³¼
        """
        url = self.API_URL_SPOKEN if use_spoken else self.API_URL_WRITTEN
        
        # NER ë¶„ì„ ìš”ì²­
        request_json = {
            "argument": {
                "text": text,
                "analysis_code": "ner"  # ê°œì²´ëª… ì¸ì‹
            }
        }
        
        try:
            response = self.http.request(
                "POST",
                url,
                headers={
                    "Content-Type": "application/json; charset=UTF-8",
                    "Authorization": self.api_key
                },
                body=json.dumps(request_json)
            )
            
            if response.status == 200:
                result = json.loads(response.data.decode("utf-8"))
                if result.get("result", -1) == 0:
                    return result.get("return_object", {})
                else:
                    print(f"âŒ API ì˜¤ë¥˜: {result.get('reason', 'Unknown error')}")
                    return {}
            else:
                print(f"âŒ HTTP ì˜¤ë¥˜: {response.status}")
                return {}
                
        except Exception as e:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def extract_entities(self, text: str, use_spoken: bool = False) -> List[PIIEntity]:
        """
        ETRI NERì„ ì‚¬ìš©í•œ ê°œì²´ëª… ì¶”ì¶œ (ì •í™•í•œ ìœ„ì¹˜ ê³„ì‚° í¬í•¨)
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            use_spoken: êµ¬ì–´ì²´ ëª¨ë“œ
        
        Returns:
            PIIEntity ë¦¬ìŠ¤íŠ¸
        """
        result = self.analyze(text, use_spoken)
        entities = []
        
        if not result:
            return entities
        
        # ë¬¸ì¥ë³„ ì²˜ë¦¬
        current_pos = 0  # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œì˜ í˜„ì¬ ìœ„ì¹˜
        
        for sentence in result.get("sentence", []):
            sentence_text = sentence.get("text", "")
            sentence_start = text.find(sentence_text, current_pos)
            
            if sentence_start == -1:
                continue
            
            # í˜•íƒœì†Œ ìœ„ì¹˜ ì •ë³´ êµ¬ì¶•
            morp_positions = []
            morp_offset = 0
            
            for morp_item in sentence.get("morp", []):
                morp_text = morp_item.get("lemma", "")
                morp_start = sentence_text.find(morp_text, morp_offset)
                if morp_start != -1:
                    morp_positions.append({
                        "id": morp_item.get("id"),
                        "text": morp_text,
                        "start": sentence_start + morp_start,
                        "end": sentence_start + morp_start + len(morp_text)
                    })
                    morp_offset = morp_start + len(morp_text)
            
            # NE (Named Entity) ì •ë³´ ì¶”ì¶œ
            for ne in sentence.get("NE", []):
                ne_type = ne.get("type", "")
                ne_text = ne.get("text", "")
                
                # PII ê´€ë ¨ íƒœê·¸ë§Œ ì²˜ë¦¬
                if ne_type in self.TAG_TO_PII:
                    label, subtype = self.TAG_TO_PII[ne_type]
                    
                    # begin, endëŠ” í˜•íƒœì†Œ ID ì°¸ì¡°
                    begin_id = ne.get("begin", 0)
                    end_id = ne.get("end", 0)
                    
                    # í˜•íƒœì†Œ IDë¡œ ì‹¤ì œ ìœ„ì¹˜ ì°¾ê¸°
                    ne_start = -1
                    ne_end = -1
                    
                    for morp_pos in morp_positions:
                        if morp_pos["id"] == begin_id:
                            ne_start = morp_pos["start"]
                        if morp_pos["id"] == end_id:
                            ne_end = morp_pos["end"]
                    
                    # ìœ„ì¹˜ë¥¼ ëª» ì°¾ì€ ê²½ìš° í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
                    if ne_start == -1 or ne_end == -1:
                        found_pos = text.find(ne_text, current_pos)
                        if found_pos != -1:
                            ne_start = found_pos
                            ne_end = found_pos + len(ne_text)
                    
                    if ne_start != -1 and ne_end != -1:
                        entities.append(PIIEntity(
                            text=ne_text,
                            label=label,
                            subtype=subtype,
                            start=ne_start,
                            end=ne_end,
                            score=0.95,  # ETRI NERì€ ë†’ì€ ì‹ ë¢°ë„
                            source="etri",
                            metadata={
                                "etri_tag": ne_type,
                                "sentence_id": sentence.get("id")
                            }
                        ))
            
            current_pos = sentence_start + len(sentence_text)
        
        return entities


class SupplementaryRegexDetector:
    """ETRIê°€ ë†“ì¹  ìˆ˜ ìˆëŠ” íŒ¨í„´ì„ ë³´ì™„í•˜ëŠ” ì •ê·œì‹ íƒì§€ê¸°"""
    
    # í•œêµ­ íŠ¹í™” íŒ¨í„´ë“¤
    PATTERNS = [
        # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ (ETRIê°€ ì˜ ëª» ì¡ëŠ” ê²½ìš°ê°€ ìˆìŒ)
        (r'\b\d{6}[-\s]?\d{7}\b', "ì‹ ì›", "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸"),
        
        # ê³„ì¢Œë²ˆí˜¸ (ì€í–‰ëª…ê³¼ í•¨ê»˜)
        (r'(?:êµ­ë¯¼|ì‹ í•œ|ìš°ë¦¬|í•˜ë‚˜|ê¸°ì—…|ë†í˜‘|ì¹´ì¹´ì˜¤ë±…í¬|í† ìŠ¤ë±…í¬)\s*\d{2,6}[-\s]\d{2,6}[-\s]\d{2,6}', "ê¸ˆìœµ", "ê³„ì¢Œë²ˆí˜¸"),
        
        # ì‹ ìš©ì¹´ë“œë²ˆí˜¸
        (r'\b\d{4}[-\s]\d{4}[-\s]\d{4}[-\s]\d{4}\b', "ê¸ˆìœµ", "ì¹´ë“œë²ˆí˜¸"),
        
        # ìš´ì „ë©´í—ˆë²ˆí˜¸
        (r'\b\d{2}[-\s]\d{6}[-\s]\d{2}\b', "ì‹ ì›", "ìš´ì „ë©´í—ˆ"),
        
        # ì—¬ê¶Œë²ˆí˜¸
        (r'\b[MS]\d{8}\b', "ì‹ ì›", "ì—¬ê¶Œë²ˆí˜¸"),
        
        # ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸
        (r'\b\d{3}[-\s]\d{2}[-\s]\d{5}\b', "ì‹ ì›", "ì‚¬ì—…ìë²ˆí˜¸"),
        
        # IP ì£¼ì†Œ
        (r'\b(?:\d{1,3}\.){3}\d{1,3}\b', "URL", "IPì£¼ì†Œ"),
    ]
    
    def detect(self, text: str, etri_entities: List[PIIEntity]) -> List[PIIEntity]:
        """
        ETRIê°€ ë†“ì¹œ íŒ¨í„´ íƒì§€ (ì¤‘ë³µ ì œê±°)
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            etri_entities: ETRIê°€ ì°¾ì€ ì—”í‹°í‹°ë“¤
        
        Returns:
            ì¶”ê°€ PIIEntity ë¦¬ìŠ¤íŠ¸
        """
        additional_entities = []
        
        # ETRIê°€ ì°¾ì€ ì˜ì—­ ê¸°ë¡
        covered_ranges = set()
        for entity in etri_entities:
            for i in range(entity.start, entity.end):
                covered_ranges.add(i)
        
        # íŒ¨í„´ ë§¤ì¹­
        for pattern, label, subtype in self.PATTERNS:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                start, end = match.span()
                
                # ETRIê°€ ì´ë¯¸ ì°¾ì€ ì˜ì—­ì¸ì§€ í™•ì¸
                if any(i in covered_ranges for i in range(start, end)):
                    continue
                
                additional_entities.append(PIIEntity(
                    text=match.group(),
                    label=label,
                    subtype=subtype,
                    start=start,
                    end=end,
                    score=0.85,
                    source="regex",
                    metadata={"pattern": pattern}
                ))
        
        return additional_entities


class EnhancedPIIDetector:
    """ETRI ì¤‘ì‹¬ì˜ í–¥ìƒëœ PII íƒì§€ê¸°"""
    
    def __init__(self, etri_api_key: str):
        """
        Args:
            etri_api_key: ETRI API í‚¤
        """
        self.etri = ETRILanguageAnalyzer(etri_api_key)
        self.regex = SupplementaryRegexDetector()
    
    def detect(self, text: str, use_spoken: bool = False) -> List[PIIEntity]:
        """
        ETRI ì¤‘ì‹¬ PII íƒì§€
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            use_spoken: êµ¬ì–´ì²´ ëª¨ë“œ
        
        Returns:
            í†µí•©ëœ PIIEntity ë¦¬ìŠ¤íŠ¸
        """
        print("ğŸ¤– ETRI NER API í˜¸ì¶œ ì¤‘...")
        
        # 1. ETRI NERì´ ë©”ì¸ (ë†’ì€ ì •í™•ë„)
        etri_entities = self.etri.extract_entities(text, use_spoken)
        print(f"  â†’ ETRI: {len(etri_entities)}ê°œ íƒì§€")
        
        # 2. ì •ê·œì‹ìœ¼ë¡œ ë³´ì™„ (ETRIê°€ ë†“ì¹œ ê²ƒë§Œ)
        print("ğŸ” ë³´ì™„ íŒ¨í„´ ê²€ì‚¬ ì¤‘...")
        additional_entities = self.regex.detect(text, etri_entities)
        print(f"  â†’ ì¶”ê°€: {len(additional_entities)}ê°œ íƒì§€")
        
        # 3. í†µí•©
        all_entities = etri_entities + additional_entities
        
        # 4. í›„ì²˜ë¦¬: ê²¹ì¹˜ëŠ” ì—”í‹°í‹° ì •ë¦¬
        merged_entities = self._merge_overlapping(all_entities)
        print(f"âœ… ìµœì¢…: {len(merged_entities)}ê°œ PII í™•ì •")
        
        return merged_entities
    
    def _merge_overlapping(self, entities: List[PIIEntity]) -> List[PIIEntity]:
        """
        ê²¹ì¹˜ëŠ” ì—”í‹°í‹° ë³‘í•© (ETRI ìš°ì„ )
        """
        if not entities:
            return []
        
        # ì •ë ¬: ì‹œì‘ ìœ„ì¹˜, ETRI ìš°ì„ , ê¸´ ê²ƒ ìš°ì„ 
        entities.sort(key=lambda e: (
            e.start,
            0 if e.source == "etri" else 1,
            -(e.end - e.start)
        ))
        
        merged = []
        for entity in entities:
            # ê²¹ì¹˜ëŠ” ê¸°ì¡´ ì—”í‹°í‹° í™•ì¸
            overlap = False
            for existing in merged:
                if not (entity.end <= existing.start or entity.start >= existing.end):
                    # ê²¹ì¹¨ - ETRIê°€ ìš°ì„ 
                    if entity.source == "etri" and existing.source != "etri":
                        merged.remove(existing)
                        merged.append(entity)
                    overlap = True
                    break
            
            if not overlap:
                merged.append(entity)
        
        # ìµœì¢… ì •ë ¬
        merged.sort(key=lambda e: e.start)
        return merged
    
    def format_results(self, entities: List[PIIEntity]) -> Dict:
        """
        ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
        """
        result = defaultdict(list)
        
        for entity in entities:
            category = f"{entity.label}"
            if entity.subtype:
                category += f" ({entity.subtype})"
            
            result[category].append({
                "text": entity.text,
                "position": f"{entity.start}-{entity.end}",
                "source": entity.source,
                "confidence": f"{entity.score:.0%}"
            })
        
        # í†µê³„ ì¶”ê°€
        result["_statistics"] = {
            "total": len(entities),
            "by_source": defaultdict(int),
            "by_label": defaultdict(int)
        }
        
        for entity in entities:
            result["_statistics"]["by_source"][entity.source] += 1
            result["_statistics"]["by_label"][entity.label] += 1
        
        return dict(result)


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    test_text = """
    ì•ˆë…•í•˜ì„¸ìš”, ê¹€ë¯¼ìˆ˜ì…ë‹ˆë‹¤. ì œ ì—°ë½ì²˜ëŠ” 010-1234-5678ì´ê³ , 
    ì´ë©”ì¼ì€ minsu.kim@example.comì…ë‹ˆë‹¤. 
    ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123ì— ìˆëŠ” ì‚¼ì„±ì „ìì—ì„œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    ê³„ì¢Œë²ˆí˜¸ëŠ” ìš°ë¦¬ì€í–‰ 1002-345-678901ì…ë‹ˆë‹¤.
    ì£¼ë¯¼ë²ˆí˜¸ëŠ” 801010-1234567ì´ê³ ìš”.
    ë‹¤ìŒ ë¯¸íŒ…ì€ 2025-08-15 ì˜¤í›„ 3ì‹œì…ë‹ˆë‹¤.
    """
    
    # API í‚¤ ì„¤ì •
    import os
    api_key = os.getenv("ETRI_API_KEY", "YOUR_API_KEY")
    
    if api_key == "YOUR_API_KEY":
        print("âš ï¸ ETRI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        print("export ETRI_API_KEY='your_actual_key'")
    else:
        # íƒì§€ê¸° ìƒì„± ë° ì‹¤í–‰
        detector = EnhancedPIIDetector(api_key)
        entities = detector.detect(test_text, use_spoken=False)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*50)
        print("ğŸ“Š PII íƒì§€ ê²°ê³¼")
        print("="*50)
        
        formatted = detector.format_results(entities)
        
        # í†µê³„ ì¶œë ¥
        stats = formatted.pop("_statistics")
        print(f"\nğŸ“ˆ í†µê³„:")
        print(f"  â€¢ ì „ì²´: {stats['total']}ê°œ")
        print(f"  â€¢ ETRI: {stats['by_source'].get('etri', 0)}ê°œ")
        print(f"  â€¢ ì •ê·œì‹: {stats['by_source'].get('regex', 0)}ê°œ")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì¶œë ¥
        for category, items in formatted.items():
            print(f"\nğŸ·ï¸ {category}:")
            for item in items:
                print(f"  â€¢ '{item['text']}' (ìœ„ì¹˜: {item['position']}, ì¶œì²˜: {item['source']}, ì‹ ë¢°ë„: {item['confidence']})")