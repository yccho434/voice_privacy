# integrated_pipeline.py
"""
ìŒì„± í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ í†µí•© íŒŒì´í”„ë¼ì¸
1ë‹¨ê³„(ìŒì„±í–¥ìƒ) â†’ 2ë‹¨ê³„(STT) â†’ 3ë‹¨ê³„(ë³´ì •) â†’ 4ë‹¨ê³„(PIIíƒì§€) â†’ 5ë‹¨ê³„(ë§ˆìŠ¤í‚¹)
"""

import os
import json
import tempfile
import sys
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field, asdict
from datetime import datetime

# privacy-pii ê²½ë¡œ ì¶”ê°€
PRIVACY_PII_PATH = Path(__file__).parent / "privacy-pii" / "app"
sys.path.insert(0, str(PRIVACY_PII_PATH))

# ê° ë‹¨ê³„ ëª¨ë“ˆ ì„í¬íŠ¸
from audio_enhancer import AudioEnhancer
from speech_to_text import ETRISpeechToText
from conservative_corrector import ConservativeCorrector, InteractiveReviewer
from etri_ner_detector import EnhancedPIIDetector
from detectors.regex_patterns import detect_by_regex
from detectors.keyword_rules import detect_by_keywords
from pii_masker import PIIMasker, MaskingResult


@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    # API í‚¤
    etri_stt_key: str
    etri_ner_key: str
    openai_key: str
    
    # ê° ë‹¨ê³„ ì„¤ì •
    enhance_audio: bool = True
    use_context_analysis: bool = True
    use_etri_ner: bool = True
    save_intermediate: bool = True
    
    # ê²½ë¡œ
    output_dir: str = "./pipeline_output"
    temp_dir: str = "./temp"


@dataclass
class PipelineResult:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼"""
    session_id: str
    timestamp: str
    
    # ê° ë‹¨ê³„ ê²°ê³¼
    audio_enhancement: Optional[Dict] = None
    speech_to_text: Optional[Dict] = None
    text_correction: Optional[Dict] = None
    pii_detection: Optional[Dict] = None
    masking: Optional[Dict] = None
    
    # ìµœì¢… ê²°ê³¼
    original_audio_path: str = ""
    enhanced_audio_path: str = ""
    original_text: str = ""
    corrected_text: str = ""
    masked_text: str = ""
    
    # ë©”íƒ€ë°ì´í„°
    processing_time: Dict = field(default_factory=dict)
    errors: List[str] = field(default_factory=list)


class IntegratedPipeline:
    """í†µí•© íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir = Path(config.output_dir) / self.session_id
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ê° ë‹¨ê³„ ì´ˆê¸°í™”
        self._init_components()
    
    def _init_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        # 1ë‹¨ê³„: ìŒì„± í–¥ìƒ
        self.audio_enhancer = AudioEnhancer(target_sr=16000)
        
        # 2ë‹¨ê³„: STT
        self.stt = ETRISpeechToText(self.config.etri_stt_key)
        
        # 3ë‹¨ê³„: í…ìŠ¤íŠ¸ ë³´ì •
        self.text_corrector = ConservativeCorrector(self.config.openai_key)
        self.text_reviewer = InteractiveReviewer()
        
        # 4ë‹¨ê³„: PII íƒì§€
        if self.config.use_etri_ner:
            self.pii_detector = EnhancedPIIDetector(self.config.etri_ner_key)
        else:
            self.pii_detector = None
        
        # 5ë‹¨ê³„: ë§ˆìŠ¤í‚¹
        self.masker = PIIMasker(
            save_mapping=True,
            mapping_dir=str(self.output_dir / "masking")
        )
    
    def process(self,
                audio_path: str,
                masking_rules: Optional[Dict] = None,
                progress_callback: Optional[callable] = None) -> PipelineResult:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            audio_path: ì…ë ¥ ìŒì„± íŒŒì¼
            masking_rules: ë§ˆìŠ¤í‚¹ ê·œì¹™ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± (step, total, message)
        
        Returns:
            PipelineResult
        """
        import time
        
        result = PipelineResult(
            session_id=self.session_id,
            timestamp=datetime.now().isoformat(),
            original_audio_path=audio_path
        )
        
        total_steps = 5
        current_step = 0
        
        try:
            # 1ë‹¨ê³„: ìŒì„± í’ˆì§ˆ í–¥ìƒ
            if self.config.enhance_audio:
                current_step += 1
                if progress_callback:
                    progress_callback(current_step, total_steps, "ğŸµ ìŒì„± í’ˆì§ˆ í–¥ìƒ ì¤‘...")
                
                start_time = time.time()
                enhanced_path = self.output_dir / "enhanced_audio.wav"
                
                enhanced_path, metrics = self.audio_enhancer.enhance(
                    audio_path,
                    str(enhanced_path),
                    visualize=False
                )
                
                result.audio_enhancement = metrics
                result.enhanced_audio_path = enhanced_path
                result.processing_time["audio_enhancement"] = time.time() - start_time
                
                audio_for_stt = enhanced_path
            else:
                audio_for_stt = audio_path
            
            # 2ë‹¨ê³„: ìŒì„± ì¸ì‹
            current_step += 1
            if progress_callback:
                progress_callback(current_step, total_steps, "ğŸ¤ ìŒì„± ì¸ì‹ ì¤‘...")
            
            start_time = time.time()
            
            stt_result = self.stt.recognize_long_audio(
                audio_for_stt,
                language="korean",
                debug_mode=False
            )
            
            if not stt_result["success"]:
                raise Exception(f"STT ì‹¤íŒ¨: {stt_result.get('error')}")
            
            result.speech_to_text = stt_result
            result.original_text = stt_result["text"]
            result.processing_time["speech_to_text"] = time.time() - start_time
            
            # 3ë‹¨ê³„: í…ìŠ¤íŠ¸ ë³´ì •
            current_step += 1
            if progress_callback:
                progress_callback(current_step, total_steps, "âœï¸ í…ìŠ¤íŠ¸ ë³´ì • ì¤‘...")
            
            start_time = time.time()
            
            correction_result = self.text_corrector.correct(
                result.original_text,
                use_context_analysis=self.config.use_context_analysis
            )
            
            result.text_correction = {
                "corrected_text": correction_result.corrected_text,
                "suspicious_parts": len(correction_result.suspicious_parts),
                "auto_corrections": correction_result.auto_corrections,
                "needs_review": correction_result.needs_review
            }
            result.corrected_text = correction_result.corrected_text
            result.processing_time["text_correction"] = time.time() - start_time
            
            # 4ë‹¨ê³„: PII íƒì§€
            current_step += 1
            if progress_callback:
                progress_callback(current_step, total_steps, "ğŸ” ê°œì¸ì •ë³´ íƒì§€ ì¤‘...")
            
            start_time = time.time()
            
            if self.config.use_etri_ner and self.pii_detector:
                # ETRI NER ì‚¬ìš©
                entities = self.pii_detector.detect(
                    result.corrected_text,
                    use_spoken=True  # êµ¬ì–´ì²´ ëª¨ë“œ
                )
                # entitiesë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                entities_list = []
                for entity in entities:
                    if hasattr(entity, '__dict__'):
                        entities_list.append(entity.__dict__)
                    elif isinstance(entity, dict):
                        entities_list.append(entity)
                    else:
                        # PIIEntity ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                        entities_list.append({
                            "text": entity.text,
                            "label": entity.label,
                            "subtype": entity.subtype,
                            "start": entity.start,
                            "end": entity.end,
                            "score": entity.score,
                            "source": entity.source,
                            "label_adjusted": entity.label
                        })
                entities = entities_list
            else:
                # ì •ê·œì‹ + í‚¤ì›Œë“œë§Œ ì‚¬ìš©
                regex_hits = detect_by_regex(result.corrected_text)
                entities = detect_by_keywords(result.corrected_text, regex_hits)
            
            result.pii_detection = {
                "total_entities": len(entities),
                "entities": entities
            }
            result.processing_time["pii_detection"] = time.time() - start_time
            
            # 5ë‹¨ê³„: ë§ˆìŠ¤í‚¹
            current_step += 1
            if progress_callback:
                progress_callback(current_step, total_steps, "ğŸ­ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ ì¤‘...")
            
            start_time = time.time()
            
            # ê¸°ë³¸ ë§ˆìŠ¤í‚¹ ê·œì¹™ (ì‚¬ìš©ì ì§€ì • ì—†ìœ¼ë©´)
            if masking_rules is None:
                masking_rules = {
                    "mode": "advanced",
                    "label_rules": {
                        "ì´ë¦„": "[ì´ë¦„]",
                        "ë²ˆí˜¸": "[ì „í™”ë²ˆí˜¸]",
                        "ì£¼ì†Œ": "[ì£¼ì†Œ]",
                        "ê³„ì •": "[ì´ë©”ì¼]",
                        "ê¸ˆìœµ": "[ê³„ì¢Œì •ë³´]",
                        "URL": "[ë§í¬]",
                        "ì‹ ì›": "[ê°œì¸ì •ë³´]",
                        "ì†Œì†": "[ì†Œì†]"
                    },
                    "default": "[ê°œì¸ì •ë³´]"
                }
            
            # ë§ˆìŠ¤í‚¹ ì‹¤í–‰
            masking_result = self.masker.mask(
                result.corrected_text,
                entities,  # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ë¨
                masking_rules
            )
            
            # MaskingResult ê°ì²´ ì²˜ë¦¬
            if isinstance(masking_result, MaskingResult):
                result.masking = {
                    "masked_text": masking_result.masked_text,
                    "total_masked": masking_result.stats.get("total", 0),
                    "mapping_file": masking_result.mapping_file
                }
                result.masked_text = masking_result.masked_text
            else:
                # ì˜ˆì™¸ ì²˜ë¦¬
                result.masking = {
                    "masked_text": result.corrected_text,
                    "total_masked": 0,
                    "mapping_file": None
                }
                result.masked_text = result.corrected_text
            
            result.processing_time["masking"] = time.time() - start_time
            
            # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
            if self.config.save_intermediate:
                self._save_intermediate_results(result)
            
            if progress_callback:
                progress_callback(total_steps, total_steps, "âœ… ì™„ë£Œ!")
            
        except Exception as e:
            result.errors.append(str(e))
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        
        return result
    
    def _save_intermediate_results(self, result: PipelineResult):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        # í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ ì €ì¥
        texts_dir = self.output_dir / "texts"
        texts_dir.mkdir(exist_ok=True)
        
        # ì›ë³¸ í…ìŠ¤íŠ¸
        if result.original_text:
            with open(texts_dir / "1_original.txt", "w", encoding="utf-8") as f:
                f.write(result.original_text)
        
        # ë³´ì •ëœ í…ìŠ¤íŠ¸
        if result.corrected_text:
            with open(texts_dir / "2_corrected.txt", "w", encoding="utf-8") as f:
                f.write(result.corrected_text)
        
        # ë§ˆìŠ¤í‚¹ëœ í…ìŠ¤íŠ¸
        if result.masked_text:
            with open(texts_dir / "3_masked.txt", "w", encoding="utf-8") as f:
                f.write(result.masked_text)
        
        # ì „ì²´ ê²°ê³¼ JSON
        result_dict = asdict(result)
        with open(self.output_dir / "pipeline_result.json", "w", encoding="utf-8") as f:
            json.dump(result_dict, f, ensure_ascii=False, indent=2, default=str)